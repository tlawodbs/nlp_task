{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1A_XWTiTE6rB12VruhSzoIeSvXz3PITup","authorship_tag":"ABX9TyOL9C/exZTph1mdrR5Vm3ZF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"38e049934cef4df1988f4d24e2979fc8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_36b3c0ba69434efd806f0232b61eb36d","IPY_MODEL_e1904302eee54c4887ec74b1ae025d06","IPY_MODEL_52cbfc651c224133a958f684f3274a5c"],"layout":"IPY_MODEL_2bcc294d42d94f0b8be54b00efe0bf1e"}},"36b3c0ba69434efd806f0232b61eb36d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9c10ea42be3940ecb26916486cf615db","placeholder":"​","style":"IPY_MODEL_aca4be34c25545caa9daee2c8244f732","value":"100%"}},"e1904302eee54c4887ec74b1ae025d06":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9fd5148963af4d65bc1d0943eb402a70","max":100,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b8db0b470b3349e188bc272c1c8225f9","value":100}},"52cbfc651c224133a958f684f3274a5c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_16374e57a4774dcd8e373187e7299397","placeholder":"​","style":"IPY_MODEL_0dacebf5be324a6f8fb04718c80ab60b","value":" 100/100 [00:00&lt;00:00, 299.13it/s]"}},"2bcc294d42d94f0b8be54b00efe0bf1e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9c10ea42be3940ecb26916486cf615db":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aca4be34c25545caa9daee2c8244f732":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9fd5148963af4d65bc1d0943eb402a70":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b8db0b470b3349e188bc272c1c8225f9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"16374e57a4774dcd8e373187e7299397":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0dacebf5be324a6f8fb04718c80ab60b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a7177a1861bd4b4791aae5d58a155f56":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_08d975b6632b4514a610d85d533f16fa","IPY_MODEL_150a59ae8ef247bca80504ff4e2e81da","IPY_MODEL_f9bfc1f515ca46cebd6bddf001fd9daf"],"layout":"IPY_MODEL_9214b25ff70344de876312a8489de184"}},"08d975b6632b4514a610d85d533f16fa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0719aecfc3cf4b07bc3af4b43146cfba","placeholder":"​","style":"IPY_MODEL_5716f9c9a0f943cf92d27d56dce7c478","value":"Downloading: 100%"}},"150a59ae8ef247bca80504ff4e2e81da":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1f1e4c91c9014c0d97017ddeb409d621","max":445025130,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8274a49d49a04a77bc1c21dbe185b27b","value":445025130}},"f9bfc1f515ca46cebd6bddf001fd9daf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_72e14d8181d64a75a3193a662026ff20","placeholder":"​","style":"IPY_MODEL_4821ba337781416a8a3f4d0b870a8c96","value":" 424M/424M [00:06&lt;00:00, 84.0MB/s]"}},"9214b25ff70344de876312a8489de184":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0719aecfc3cf4b07bc3af4b43146cfba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5716f9c9a0f943cf92d27d56dce7c478":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1f1e4c91c9014c0d97017ddeb409d621":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8274a49d49a04a77bc1c21dbe185b27b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"72e14d8181d64a75a3193a662026ff20":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4821ba337781416a8a3f4d0b870a8c96":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7aeb8854417d4b10940731611ba673de":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f341365ce5fc44ea86828ba386e28b69","IPY_MODEL_9d1ee1609a2a4f0caebae35613feb6e7","IPY_MODEL_5e0ebba18b6d4cf8b0619bd4870c9d6c"],"layout":"IPY_MODEL_4c57a17d6af04919b8e1bd9c0dc83149"}},"f341365ce5fc44ea86828ba386e28b69":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f76c8f84fabc48ae8d0df1502224d6c2","placeholder":"​","style":"IPY_MODEL_25b3560b33474125b4711ab7033e3484","value":"100%"}},"9d1ee1609a2a4f0caebae35613feb6e7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e2afaffc6da24720a7e7f0526624db1f","max":5841,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4df4306e053743bbb1a6088e479d69fc","value":5841}},"5e0ebba18b6d4cf8b0619bd4870c9d6c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4a6910c845f14e92b308551cb7ddc55c","placeholder":"​","style":"IPY_MODEL_dde38e9ef06a4cb48d5b2a1a8d8f20f1","value":" 5841/5841 [00:23&lt;00:00, 269.85it/s]"}},"4c57a17d6af04919b8e1bd9c0dc83149":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f76c8f84fabc48ae8d0df1502224d6c2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"25b3560b33474125b4711ab7033e3484":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e2afaffc6da24720a7e7f0526624db1f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4df4306e053743bbb1a6088e479d69fc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4a6910c845f14e92b308551cb7ddc55c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dde38e9ef06a4cb48d5b2a1a8d8f20f1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["#Setting"],"metadata":{"id":"02IrD8zDzUes"}},{"cell_type":"code","execution_count":79,"metadata":{"id":"clwzxjiQAZWw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707149745385,"user_tz":-540,"elapsed":5355,"user":{"displayName":"심재윤","userId":"07193421856804560452"}},"outputId":"e3c0d9c2-6965-4806-d68f-9e560b84385f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers==4.17 in /usr/local/lib/python3.10/dist-packages (4.17.0)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.16.1)\n","Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.26.1)\n","Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.17) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.17) (0.20.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.17) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.17) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.17) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.17) (2023.12.25)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.17) (2.31.0)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.10/dist-packages (from transformers==4.17) (0.1.1)\n","Requirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.17) (0.15.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.17) (4.66.1)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (10.0.1)\n","Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n","Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n","Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu121)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.2)\n","Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.18.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.17) (4.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.17) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.17) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.17) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.17) (2023.11.17)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sacremoses->transformers==4.17) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sacremoses->transformers==4.17) (1.3.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.4)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"]}],"source":["!pip install transformers==4.17 datasets accelerate evaluate"]},{"cell_type":"code","source":["from datasets import load_dataset\n","\n","dataset = load_dataset('klue', 'mrc')\n","dataset"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UrLPInmOeXo1","executionInfo":{"status":"ok","timestamp":1707149746858,"user_tz":-540,"elapsed":1485,"user":{"displayName":"심재윤","userId":"07193421856804560452"}},"outputId":"fba11e38-b892-48e5-9cab-0ca90c63f1a7"},"execution_count":80,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['title', 'context', 'news_category', 'source', 'guid', 'is_impossible', 'question_type', 'question', 'answers'],\n","        num_rows: 17554\n","    })\n","    validation: Dataset({\n","        features: ['title', 'context', 'news_category', 'source', 'guid', 'is_impossible', 'question_type', 'question', 'answers'],\n","        num_rows: 5841\n","    })\n","})"]},"metadata":{},"execution_count":80}]},{"cell_type":"markdown","metadata":{"id":"peBXY9Mb-YrV"},"source":["# Fine-tune a pretrained model"]},{"cell_type":"markdown","metadata":{"id":"RDRA_mp3-YrW"},"source":["## Prepare a dataset"]},{"cell_type":"code","source":["dataset[\"train\"][0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hfyB7_K4_xMi","executionInfo":{"status":"ok","timestamp":1707149746858,"user_tz":-540,"elapsed":8,"user":{"displayName":"심재윤","userId":"07193421856804560452"}},"outputId":"ea322668-4098-4069-eb38-ec9e57b0b56d"},"execution_count":81,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'title': '제주도 장마 시작 … 중부는 이달 말부터',\n"," 'context': '올여름 장마가 17일 제주도에서 시작됐다. 서울 등 중부지방은 예년보다 사나흘 정도 늦은 이달 말께 장마가 시작될 전망이다.17일 기상청에 따르면 제주도 남쪽 먼바다에 있는 장마전선의 영향으로 이날 제주도 산간 및 내륙지역에 호우주의보가 내려지면서 곳곳에 100㎜에 육박하는 많은 비가 내렸다. 제주의 장마는 평년보다 2~3일, 지난해보다는 하루 일찍 시작됐다. 장마는 고온다습한 북태평양 기단과 한랭 습윤한 오호츠크해 기단이 만나 형성되는 장마전선에서 내리는 비를 뜻한다.장마전선은 18일 제주도 먼 남쪽 해상으로 내려갔다가 20일께 다시 북상해 전남 남해안까지 영향을 줄 것으로 보인다. 이에 따라 20~21일 남부지방에도 예년보다 사흘 정도 장마가 일찍 찾아올 전망이다. 그러나 장마전선을 밀어올리는 북태평양 고기압 세력이 약해 서울 등 중부지방은 평년보다 사나흘가량 늦은 이달 말부터 장마가 시작될 것이라는 게 기상청의 설명이다. 장마전선은 이후 한 달가량 한반도 중남부를 오르내리며 곳곳에 비를 뿌릴 전망이다. 최근 30년간 평균치에 따르면 중부지방의 장마 시작일은 6월24~25일이었으며 장마기간은 32일, 강수일수는 17.2일이었다.기상청은 올해 장마기간의 평균 강수량이 350~400㎜로 평년과 비슷하거나 적을 것으로 내다봤다. 브라질 월드컵 한국과 러시아의 경기가 열리는 18일 오전 서울은 대체로 구름이 많이 끼지만 비는 오지 않을 것으로 예상돼 거리 응원에는 지장이 없을 전망이다.',\n"," 'news_category': '종합',\n"," 'source': 'hankyung',\n"," 'guid': 'klue-mrc-v1_train_12759',\n"," 'is_impossible': False,\n"," 'question_type': 1,\n"," 'question': '북태평양 기단과 오호츠크해 기단이 만나 국내에 머무르는 기간은?',\n"," 'answers': {'answer_start': [478, 478], 'text': ['한 달가량', '한 달']}}"]},"metadata":{},"execution_count":81}]},{"cell_type":"code","source":["dataset[\"validation\"][0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y4wWdMe3L77h","executionInfo":{"status":"ok","timestamp":1707149746859,"user_tz":-540,"elapsed":7,"user":{"displayName":"심재윤","userId":"07193421856804560452"}},"outputId":"c508061a-d3aa-466d-c154-b8a0fbc19801"},"execution_count":82,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'title': 'BMW 코리아, 창립 25주년 기념 ‘BMW 코리아 25주년 에디션’ 한정 출시',\n"," 'context': 'BMW 코리아(대표 한상윤)는 창립 25주년을 기념하는 ‘BMW 코리아 25주년 에디션’을 한정 출시한다고 밝혔다. 이번 BMW 코리아 25주년 에디션(이하 25주년 에디션)은 BMW 3시리즈와 5시리즈, 7시리즈, 8시리즈 총 4종, 6개 모델로 출시되며, BMW 클래식 모델들로 선보인 바 있는 헤리티지 컬러가 차체에 적용돼 레트로한 느낌과 신구의 조화가 어우러진 차별화된 매력을 자랑한다. 먼저 뉴 320i 및 뉴 320d 25주년 에디션은 트림에 따라 옥스포드 그린(50대 한정) 또는 마카오 블루(50대 한정) 컬러가 적용된다. 럭셔리 라인에 적용되는 옥스포드 그린은 지난 1999년 3세대 3시리즈를 통해 처음 선보인 색상으로 짙은 녹색과 풍부한 펄이 오묘한 조화를 이루는 것이 특징이다. M 스포츠 패키지 트림에 적용되는 마카오 블루는 1988년 2세대 3시리즈를 통해 처음 선보인 바 있으며, 보랏빛 감도는 컬러감이 매력이다. 뉴 520d 25주년 에디션(25대 한정)은 프로즌 브릴리언트 화이트 컬러로 출시된다. BMW가 2011년에 처음 선보인 프로즌 브릴리언트 화이트는 한층 더 환하고 깊은 색감을 자랑하며, 특히 표면을 무광으로 마감해 특별함을 더했다. 뉴 530i 25주년 에디션(25대 한정)은 뉴 3시리즈 25주년 에디션에도 적용된 마카오 블루 컬러가 조합된다. 뉴 740Li 25주년 에디션(7대 한정)에는 말라카이트 그린 다크 색상이 적용된다. 잔잔하면서도 오묘한 깊은 녹색을 발산하는 말라카이트 그린 다크는 장식재로 활용되는 광물 말라카이트에서 유래됐다. 뉴 840i xDrive 그란쿠페 25주년 에디션(8대 한정)은 인도양의 맑고 투명한 에메랄드 빛을 연상케 하는 몰디브 블루 컬러로 출시된다. 특히 몰디브 블루는 지난 1993년 1세대 8시리즈에 처음으로 적용되었던 만큼 이를 오마주하는 의미를 담고 있다.',\n"," 'news_category': '자동차',\n"," 'source': 'acrofan',\n"," 'guid': 'klue-mrc-v1_dev_01891',\n"," 'is_impossible': False,\n"," 'question_type': 2,\n"," 'question': '말라카이트에서 나온 색깔을 사용한 에디션은?',\n"," 'answers': {'answer_start': [666, 666],\n","  'text': ['뉴 740Li 25주년 에디션', '뉴 740Li 25주년']}}"]},"metadata":{},"execution_count":82}]},{"cell_type":"code","source":["from transformers import AutoTokenizer\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"klue/bert-base\")\n","\n","\n","# def tokenize_function(examples):\n","#     return tokenizer(examples[\"sentence\"], padding=\"max_length\", truncation=True)"],"metadata":{"id":"UH03RaE0mLic","executionInfo":{"status":"ok","timestamp":1707149748495,"user_tz":-540,"elapsed":1641,"user":{"displayName":"심재윤","userId":"07193421856804560452"}}},"execution_count":83,"outputs":[]},{"cell_type":"markdown","source":["토크나이저에 질문과 컨텍스트를 함께 전달할 수 있으며 특수 토큰을 적절하게 삽입하여 다음과 같은 문장을 구성합니다.\n","\n","Tokenizer에 question과 context를 인자로 넣어주면, tokenizer가 special token을 적절하게 삽입하여 하나의 문장으로 만들어준다.\n","\n","그러면 레이블은 대답을 시작하고 끝내는 토큰의 인덱스가 되며, 모델은 입력에서 토큰당 하나의 시작 및 끝 로짓을 예측하도록 임무를 맡게 된다.\n","\n"],"metadata":{"id":"8dBLVipbQDQ9"}},{"cell_type":"code","source":["context = dataset[\"train\"][0][\"context\"]\n","question = dataset[\"train\"][0][\"question\"]\n","\n","#tokenizer function 이용해서 쉽게 만들 수 있다!\n","inputs = tokenizer(question, context)\n","tokenizer.decode(inputs[\"input_ids\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":183},"id":"AgB4fRPCPWm6","executionInfo":{"status":"ok","timestamp":1707149748496,"user_tz":-540,"elapsed":37,"user":{"displayName":"심재윤","userId":"07193421856804560452"}},"outputId":"2174a7b6-8ae3-4e92-fb02-8f020213adee"},"execution_count":84,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'[CLS] 북태평양 기단과 오호츠크해 기단이 만나 국내에 머무르는 기간은? [SEP] 올여름 장마가 17일 제주도에서 시작됐다. 서울 등 중부지방은 예년보다 사나흘 정도 늦은 이달 말께 장마가 시작될 전망이다. 17일 기상청에 따르면 제주도 남쪽 먼바다에 있는 장마전선의 영향으로 이날 제주도 산간 및 내륙지역에 호우주의보가 내려지면서 곳곳에 100㎜에 육박하는 많은 비가 내렸다. 제주의 장마는 평년보다 2 ~ 3일, 지난해보다는 하루 일찍 시작됐다. 장마는 고온다습한 북태평양 기단과 한랭 습윤한 오호츠크해 기단이 만나 형성되는 장마전선에서 내리는 비를 뜻한다. 장마전선은 18일 제주도 먼 남쪽 해상으로 내려갔다가 20일께 다시 북상해 전남 남해안까지 영향을 줄 것으로 보인다. 이에 따라 20 ~ 21일 남부지방에도 예년보다 사흘 정도 장마가 일찍 찾아올 전망이다. 그러나 장마전선을 밀어올리는 북태평양 고기압 세력이 약해 서울 등 중부지방은 평년보다 사나흘가량 늦은 이달 말부터 장마가 시작될 것이라는 게 기상청의 설명이다. 장마전선은 이후 한 달가량 한반도 중남부를 오르내리며 곳곳에 비를 뿌릴 전망이다. 최근 30년간 평균치에 따르면 중부지방의 장마 시작일은 6월24 ~ 25일이었으며 장마기간은 32일, 강수일수는 17. 2일이었다. 기상청은 올해 장마기간의 평균 강수량이 350 ~ 400㎜로 평년과 비슷하거나 적을 것으로 내다봤다. 브라질 월드컵 한국과 러시아의 경기가 열리는 18일 오전 서울은 대체로 구름이 많이 끼지만 비는 오지 않을 것으로 예상돼 거리 응원에는 지장이 없을 전망이다. [SEP]'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":84}]},{"cell_type":"markdown","source":["Bert model들은 input 문장의 최대 길이가 정해져있어서 max_length를 조절해주어야 한다."],"metadata":{"id":"upwqaH1cTYLT"}},{"cell_type":"code","source":["# max_length: input으로 들어갈 문장의 최대 길이 조절\n","# truncation=\"only_second\": input인 문장이 question과 context 두 개인데, 이 중에서 question만이 모델의 최대 길이를 넘을 경우 축소(truncate), 여기서 question은 유지됨\n","# stride: window size 조절\n","# return_overflowing_tokens=True: 연속적인 text block 사이에 중복되는 token을 포함하여 맥락을 유지\n","\n","inputs = tokenizer(\n","    question,\n","    context,\n","    max_length=100,\n","    truncation=\"only_second\",\n","    stride=50,\n","    return_overflowing_tokens=True,\n",")\n","\n","for ids in inputs[\"input_ids\"]:\n","    print(tokenizer.decode(ids))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"phvSKgaVRmg_","executionInfo":{"status":"ok","timestamp":1707149748496,"user_tz":-540,"elapsed":36,"user":{"displayName":"심재윤","userId":"07193421856804560452"}},"outputId":"45ff9bc1-fa5a-4b81-b4ed-154f521f3401"},"execution_count":85,"outputs":[{"output_type":"stream","name":"stdout","text":["[CLS] 북태평양 기단과 오호츠크해 기단이 만나 국내에 머무르는 기간은? [SEP] 올여름 장마가 17일 제주도에서 시작됐다. 서울 등 중부지방은 예년보다 사나흘 정도 늦은 이달 말께 장마가 시작될 전망이다. 17일 기상청에 따르면 제주도 남쪽 먼바다에 있는 장마전선의 영향으로 이날 제주도 산간 및 내륙지역에 호우주의보가 내려지면서 곳곳에 100㎜에 육박하는 많은 비가 [SEP]\n","[CLS] 북태평양 기단과 오호츠크해 기단이 만나 국내에 머무르는 기간은? [SEP]가 시작될 전망이다. 17일 기상청에 따르면 제주도 남쪽 먼바다에 있는 장마전선의 영향으로 이날 제주도 산간 및 내륙지역에 호우주의보가 내려지면서 곳곳에 100㎜에 육박하는 많은 비가 내렸다. 제주의 장마는 평년보다 2 ~ 3일, 지난해보다는 하루 일찍 시작됐다. 장마는 고온다습 [SEP]\n","[CLS] 북태평양 기단과 오호츠크해 기단이 만나 국내에 머무르는 기간은? [SEP] 내륙지역에 호우주의보가 내려지면서 곳곳에 100㎜에 육박하는 많은 비가 내렸다. 제주의 장마는 평년보다 2 ~ 3일, 지난해보다는 하루 일찍 시작됐다. 장마는 고온다습한 북태평양 기단과 한랭 습윤한 오호츠크해 기단이 만나 형성되는 장마전선에서 내리는 비를 뜻 [SEP]\n","[CLS] 북태평양 기단과 오호츠크해 기단이 만나 국내에 머무르는 기간은? [SEP]보다 2 ~ 3일, 지난해보다는 하루 일찍 시작됐다. 장마는 고온다습한 북태평양 기단과 한랭 습윤한 오호츠크해 기단이 만나 형성되는 장마전선에서 내리는 비를 뜻한다. 장마전선은 18일 제주도 먼 남쪽 해상으로 내려갔다가 20일께 다시 북상해 전남 남해안까지 영향을 줄 것 [SEP]\n","[CLS] 북태평양 기단과 오호츠크해 기단이 만나 국내에 머무르는 기간은? [SEP]윤한 오호츠크해 기단이 만나 형성되는 장마전선에서 내리는 비를 뜻한다. 장마전선은 18일 제주도 먼 남쪽 해상으로 내려갔다가 20일께 다시 북상해 전남 남해안까지 영향을 줄 것으로 보인다. 이에 따라 20 ~ 21일 남부지방에도 예년보다 사흘 정도 장마가 일찍 찾아올 전망이다. 그러나 장마전선 [SEP]\n","[CLS] 북태평양 기단과 오호츠크해 기단이 만나 국내에 머무르는 기간은? [SEP] 제주도 먼 남쪽 해상으로 내려갔다가 20일께 다시 북상해 전남 남해안까지 영향을 줄 것으로 보인다. 이에 따라 20 ~ 21일 남부지방에도 예년보다 사흘 정도 장마가 일찍 찾아올 전망이다. 그러나 장마전선을 밀어올리는 북태평양 고기압 세력이 약해 서울 등 중부지방은 평년보다 사나흘가량 늦은 이달 말부터 장마가 [SEP]\n","[CLS] 북태평양 기단과 오호츠크해 기단이 만나 국내에 머무르는 기간은? [SEP] 21일 남부지방에도 예년보다 사흘 정도 장마가 일찍 찾아올 전망이다. 그러나 장마전선을 밀어올리는 북태평양 고기압 세력이 약해 서울 등 중부지방은 평년보다 사나흘가량 늦은 이달 말부터 장마가 시작될 것이라는 게 기상청의 설명이다. 장마전선은 이후 한 달가량 한반도 중남부를 오르내리며 곳곳에 비 [SEP]\n","[CLS] 북태평양 기단과 오호츠크해 기단이 만나 국내에 머무르는 기간은? [SEP]이 약해 서울 등 중부지방은 평년보다 사나흘가량 늦은 이달 말부터 장마가 시작될 것이라는 게 기상청의 설명이다. 장마전선은 이후 한 달가량 한반도 중남부를 오르내리며 곳곳에 비를 뿌릴 전망이다. 최근 30년간 평균치에 따르면 중부지방의 장마 시작일은 6월24 ~ 25일이었 [SEP]\n","[CLS] 북태평양 기단과 오호츠크해 기단이 만나 국내에 머무르는 기간은? [SEP] 설명이다. 장마전선은 이후 한 달가량 한반도 중남부를 오르내리며 곳곳에 비를 뿌릴 전망이다. 최근 30년간 평균치에 따르면 중부지방의 장마 시작일은 6월24 ~ 25일이었으며 장마기간은 32일, 강수일수는 17. 2일이었다. 기상청은 올해 장마기간의 평균 강수량 [SEP]\n","[CLS] 북태평양 기단과 오호츠크해 기단이 만나 국내에 머무르는 기간은? [SEP]년간 평균치에 따르면 중부지방의 장마 시작일은 6월24 ~ 25일이었으며 장마기간은 32일, 강수일수는 17. 2일이었다. 기상청은 올해 장마기간의 평균 강수량이 350 ~ 400㎜로 평년과 비슷하거나 적을 것으로 내다봤다. 브라질 월드컵 한국과 러시아의 경기가 열리는 18 [SEP]\n","[CLS] 북태평양 기단과 오호츠크해 기단이 만나 국내에 머무르는 기간은? [SEP] 강수일수는 17. 2일이었다. 기상청은 올해 장마기간의 평균 강수량이 350 ~ 400㎜로 평년과 비슷하거나 적을 것으로 내다봤다. 브라질 월드컵 한국과 러시아의 경기가 열리는 18일 오전 서울은 대체로 구름이 많이 끼지만 비는 오지 않을 것으로 예상돼 거리 응원에는 지장이 없을 전망이다 [SEP]\n","[CLS] 북태평양 기단과 오호츠크해 기단이 만나 국내에 머무르는 기간은? [SEP] 비슷하거나 적을 것으로 내다봤다. 브라질 월드컵 한국과 러시아의 경기가 열리는 18일 오전 서울은 대체로 구름이 많이 끼지만 비는 오지 않을 것으로 예상돼 거리 응원에는 지장이 없을 전망이다. [SEP]\n"]}]},{"cell_type":"code","source":["#return_offsets_mapping=True는 토큰화 과정에서 각 토큰의 원본 텍스트 내 위치(오프셋) 정보를 반환, 토큰화된 결과에 대한 상세한 위치 정보가 필요할 때 유용\n","#이렇게 tokenize를 하면 inputs의 key에 overflow_to_sample_mapping이 생기는데, 이 list는 원래 text에서 max_length에 의해 나누어진 문장들이 어디서 온 문장들인지 구분해주기 위해 사용되는 list\n","#이 예시에서는 question과 context가 각각 한 문장씩 있어서 [0, 0, 0, ...] 이런 식으로 되어있지만, 만약 question과 context가 각각 3 문장이었다면 [0, 0, 0, ..., 1, 1, 1, ..., 2, 2, 2, ...] 이런 식이었을 것.\n","inputs = tokenizer(\n","    question,\n","    context,\n","    max_length=100,\n","    truncation=\"only_second\",\n","    stride=50,\n","    return_overflowing_tokens=True,\n","    return_offsets_mapping=True,\n",")\n","inputs.keys()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3iO7E6h3XbEk","executionInfo":{"status":"ok","timestamp":1707149748496,"user_tz":-540,"elapsed":33,"user":{"displayName":"심재윤","userId":"07193421856804560452"}},"outputId":"9b7fa7f0-0de1-49d2-c5e5-acb8f7ab9597"},"execution_count":86,"outputs":[{"output_type":"execute_result","data":{"text/plain":["dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'offset_mapping', 'overflow_to_sample_mapping'])"]},"metadata":{},"execution_count":86}]},{"cell_type":"code","source":["print(inputs[\"offset_mapping\"])\n","print(inputs[\"overflow_to_sample_mapping\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"idzDuAgUnt7P","executionInfo":{"status":"ok","timestamp":1707149748497,"user_tz":-540,"elapsed":32,"user":{"displayName":"심재윤","userId":"07193421856804560452"}},"outputId":"4330319c-866a-4148-8a7f-6523fccc7ed4"},"execution_count":87,"outputs":[{"output_type":"stream","name":"stdout","text":["[[(0, 0), (0, 1), (1, 4), (5, 7), (7, 8), (9, 11), (11, 12), (12, 13), (13, 14), (15, 17), (17, 18), (19, 21), (22, 24), (24, 25), (26, 29), (29, 30), (31, 33), (33, 34), (34, 35), (0, 0), (0, 1), (1, 3), (4, 6), (6, 7), (8, 10), (10, 11), (12, 15), (15, 17), (18, 20), (20, 21), (21, 22), (22, 23), (24, 26), (27, 28), (29, 31), (31, 33), (33, 34), (35, 37), (37, 38), (38, 39), (40, 42), (42, 43), (44, 46), (47, 48), (48, 49), (50, 52), (53, 54), (54, 55), (56, 58), (58, 59), (60, 62), (62, 63), (64, 66), (66, 68), (68, 69), (69, 71), (71, 72), (73, 76), (76, 77), (78, 80), (80, 81), (82, 85), (86, 88), (89, 90), (90, 92), (92, 93), (94, 95), (95, 96), (97, 99), (99, 100), (100, 101), (101, 102), (103, 105), (105, 107), (108, 110), (111, 114), (115, 117), (118, 119), (120, 122), (122, 124), (124, 125), (126, 128), (128, 130), (130, 131), (131, 132), (133, 136), (136, 138), (139, 141), (141, 142), (143, 146), (146, 147), (147, 148), (149, 151), (151, 152), (152, 153), (154, 155), (155, 156), (157, 158), (158, 159), (0, 0)], [(0, 0), (0, 1), (1, 4), (5, 7), (7, 8), (9, 11), (11, 12), (12, 13), (13, 14), (15, 17), (17, 18), (19, 21), (22, 24), (24, 25), (26, 29), (29, 30), (31, 33), (33, 34), (34, 35), (0, 0), (58, 59), (60, 62), (62, 63), (64, 66), (66, 68), (68, 69), (69, 71), (71, 72), (73, 76), (76, 77), (78, 80), (80, 81), (82, 85), (86, 88), (89, 90), (90, 92), (92, 93), (94, 95), (95, 96), (97, 99), (99, 100), (100, 101), (101, 102), (103, 105), (105, 107), (108, 110), (111, 114), (115, 117), (118, 119), (120, 122), (122, 124), (124, 125), (126, 128), (128, 130), (130, 131), (131, 132), (133, 136), (136, 138), (139, 141), (141, 142), (143, 146), (146, 147), (147, 148), (149, 151), (151, 152), (152, 153), (154, 155), (155, 156), (157, 158), (158, 159), (160, 162), (162, 163), (163, 164), (165, 167), (167, 168), (169, 171), (171, 172), (173, 175), (175, 176), (176, 177), (178, 179), (179, 180), (180, 181), (181, 182), (182, 183), (184, 187), (187, 188), (188, 190), (191, 193), (194, 196), (197, 199), (199, 200), (200, 201), (201, 202), (203, 205), (205, 206), (207, 209), (209, 210), (210, 211), (0, 0)], [(0, 0), (0, 1), (1, 4), (5, 7), (7, 8), (9, 11), (11, 12), (12, 13), (13, 14), (15, 17), (17, 18), (19, 21), (22, 24), (24, 25), (26, 29), (29, 30), (31, 33), (33, 34), (34, 35), (0, 0), (120, 122), (122, 124), (124, 125), (126, 128), (128, 130), (130, 131), (131, 132), (133, 136), (136, 138), (139, 141), (141, 142), (143, 146), (146, 147), (147, 148), (149, 151), (151, 152), (152, 153), (154, 155), (155, 156), (157, 158), (158, 159), (160, 162), (162, 163), (163, 164), (165, 167), (167, 168), (169, 171), (171, 172), (173, 175), (175, 176), (176, 177), (178, 179), (179, 180), (180, 181), (181, 182), (182, 183), (184, 187), (187, 188), (188, 190), (191, 193), (194, 196), (197, 199), (199, 200), (200, 201), (201, 202), (203, 205), (205, 206), (207, 209), (209, 210), (210, 211), (211, 212), (213, 214), (214, 217), (218, 220), (220, 221), (222, 223), (223, 224), (225, 226), (226, 227), (227, 228), (229, 231), (231, 232), (232, 233), (233, 234), (235, 237), (237, 238), (239, 241), (242, 244), (244, 245), (245, 246), (247, 249), (249, 250), (250, 251), (251, 253), (254, 256), (256, 257), (258, 259), (259, 260), (261, 262), (0, 0)], [(0, 0), (0, 1), (1, 4), (5, 7), (7, 8), (9, 11), (11, 12), (12, 13), (13, 14), (15, 17), (17, 18), (19, 21), (22, 24), (24, 25), (26, 29), (29, 30), (31, 33), (33, 34), (34, 35), (0, 0), (175, 176), (176, 177), (178, 179), (179, 180), (180, 181), (181, 182), (182, 183), (184, 187), (187, 188), (188, 190), (191, 193), (194, 196), (197, 199), (199, 200), (200, 201), (201, 202), (203, 205), (205, 206), (207, 209), (209, 210), (210, 211), (211, 212), (213, 214), (214, 217), (218, 220), (220, 221), (222, 223), (223, 224), (225, 226), (226, 227), (227, 228), (229, 231), (231, 232), (232, 233), (233, 234), (235, 237), (237, 238), (239, 241), (242, 244), (244, 245), (245, 246), (247, 249), (249, 250), (250, 251), (251, 253), (254, 256), (256, 257), (258, 259), (259, 260), (261, 262), (262, 264), (264, 265), (265, 267), (267, 268), (268, 269), (269, 270), (271, 273), (273, 274), (275, 278), (279, 280), (281, 283), (284, 286), (286, 288), (289, 292), (292, 294), (295, 297), (297, 298), (298, 299), (300, 302), (303, 305), (305, 306), (307, 309), (310, 313), (313, 314), (314, 315), (316, 318), (318, 319), (320, 321), (322, 323), (0, 0)], [(0, 0), (0, 1), (1, 4), (5, 7), (7, 8), (9, 11), (11, 12), (12, 13), (13, 14), (15, 17), (17, 18), (19, 21), (22, 24), (24, 25), (26, 29), (29, 30), (31, 33), (33, 34), (34, 35), (0, 0), (226, 227), (227, 228), (229, 231), (231, 232), (232, 233), (233, 234), (235, 237), (237, 238), (239, 241), (242, 244), (244, 245), (245, 246), (247, 249), (249, 250), (250, 251), (251, 253), (254, 256), (256, 257), (258, 259), (259, 260), (261, 262), (262, 264), (264, 265), (265, 267), (267, 268), (268, 269), (269, 270), (271, 273), (273, 274), (275, 278), (279, 280), (281, 283), (284, 286), (286, 288), (289, 292), (292, 294), (295, 297), (297, 298), (298, 299), (300, 302), (303, 305), (305, 306), (307, 309), (310, 313), (313, 314), (314, 315), (316, 318), (318, 319), (320, 321), (322, 323), (323, 325), (326, 329), (329, 330), (331, 332), (332, 333), (334, 336), (337, 339), (339, 340), (340, 342), (342, 343), (344, 346), (346, 348), (348, 350), (351, 353), (353, 354), (354, 355), (356, 358), (359, 361), (362, 364), (364, 365), (366, 368), (369, 372), (373, 375), (375, 377), (377, 378), (379, 382), (383, 385), (385, 386), (386, 387), (0, 0)], [(0, 0), (0, 1), (1, 4), (5, 7), (7, 8), (9, 11), (11, 12), (12, 13), (13, 14), (15, 17), (17, 18), (19, 21), (22, 24), (24, 25), (26, 29), (29, 30), (31, 33), (33, 34), (34, 35), (0, 0), (275, 278), (279, 280), (281, 283), (284, 286), (286, 288), (289, 292), (292, 294), (295, 297), (297, 298), (298, 299), (300, 302), (303, 305), (305, 306), (307, 309), (310, 313), (313, 314), (314, 315), (316, 318), (318, 319), (320, 321), (322, 323), (323, 325), (326, 329), (329, 330), (331, 332), (332, 333), (334, 336), (337, 339), (339, 340), (340, 342), (342, 343), (344, 346), (346, 348), (348, 350), (351, 353), (353, 354), (354, 355), (356, 358), (359, 361), (362, 364), (364, 365), (366, 368), (369, 372), (373, 375), (375, 377), (377, 378), (379, 382), (383, 385), (385, 386), (386, 387), (387, 388), (389, 391), (391, 393), (393, 394), (395, 396), (396, 399), (400, 403), (404, 406), (406, 407), (408, 410), (411, 413), (414, 415), (416, 418), (418, 420), (420, 421), (422, 424), (424, 425), (425, 426), (427, 429), (429, 430), (430, 431), (431, 432), (433, 434), (434, 435), (436, 438), (439, 440), (440, 442), (443, 445), (445, 446), (0, 0)], [(0, 0), (0, 1), (1, 4), (5, 7), (7, 8), (9, 11), (11, 12), (12, 13), (13, 14), (15, 17), (17, 18), (19, 21), (22, 24), (24, 25), (26, 29), (29, 30), (31, 33), (33, 34), (34, 35), (0, 0), (340, 342), (342, 343), (344, 346), (346, 348), (348, 350), (351, 353), (353, 354), (354, 355), (356, 358), (359, 361), (362, 364), (364, 365), (366, 368), (369, 372), (373, 375), (375, 377), (377, 378), (379, 382), (383, 385), (385, 386), (386, 387), (387, 388), (389, 391), (391, 393), (393, 394), (395, 396), (396, 399), (400, 403), (404, 406), (406, 407), (408, 410), (411, 413), (414, 415), (416, 418), (418, 420), (420, 421), (422, 424), (424, 425), (425, 426), (427, 429), (429, 430), (430, 431), (431, 432), (433, 434), (434, 435), (436, 438), (439, 440), (440, 442), (443, 445), (445, 446), (447, 449), (449, 450), (451, 452), (452, 453), (453, 455), (456, 457), (458, 461), (461, 462), (463, 465), (465, 467), (467, 468), (469, 471), (471, 472), (472, 473), (473, 474), (475, 477), (478, 479), (480, 481), (481, 482), (482, 483), (484, 487), (488, 490), (490, 491), (491, 492), (493, 497), (497, 498), (499, 501), (501, 502), (503, 504), (0, 0)], [(0, 0), (0, 1), (1, 4), (5, 7), (7, 8), (9, 11), (11, 12), (12, 13), (13, 14), (15, 17), (17, 18), (19, 21), (22, 24), (24, 25), (26, 29), (29, 30), (31, 33), (33, 34), (34, 35), (0, 0), (406, 407), (408, 410), (411, 413), (414, 415), (416, 418), (418, 420), (420, 421), (422, 424), (424, 425), (425, 426), (427, 429), (429, 430), (430, 431), (431, 432), (433, 434), (434, 435), (436, 438), (439, 440), (440, 442), (443, 445), (445, 446), (447, 449), (449, 450), (451, 452), (452, 453), (453, 455), (456, 457), (458, 461), (461, 462), (463, 465), (465, 467), (467, 468), (469, 471), (471, 472), (472, 473), (473, 474), (475, 477), (478, 479), (480, 481), (481, 482), (482, 483), (484, 487), (488, 490), (490, 491), (491, 492), (493, 497), (497, 498), (499, 501), (501, 502), (503, 504), (504, 505), (506, 507), (507, 508), (509, 511), (511, 513), (513, 514), (515, 517), (518, 520), (520, 521), (521, 522), (523, 526), (526, 527), (528, 530), (530, 531), (532, 534), (534, 536), (536, 537), (538, 540), (541, 543), (543, 544), (544, 545), (546, 547), (547, 548), (548, 550), (550, 551), (551, 553), (553, 554), (554, 555), (555, 556), (0, 0)], [(0, 0), (0, 1), (1, 4), (5, 7), (7, 8), (9, 11), (11, 12), (12, 13), (13, 14), (15, 17), (17, 18), (19, 21), (22, 24), (24, 25), (26, 29), (29, 30), (31, 33), (33, 34), (34, 35), (0, 0), (463, 465), (465, 467), (467, 468), (469, 471), (471, 472), (472, 473), (473, 474), (475, 477), (478, 479), (480, 481), (481, 482), (482, 483), (484, 487), (488, 490), (490, 491), (491, 492), (493, 497), (497, 498), (499, 501), (501, 502), (503, 504), (504, 505), (506, 507), (507, 508), (509, 511), (511, 513), (513, 514), (515, 517), (518, 520), (520, 521), (521, 522), (523, 526), (526, 527), (528, 530), (530, 531), (532, 534), (534, 536), (536, 537), (538, 540), (541, 543), (543, 544), (544, 545), (546, 547), (547, 548), (548, 550), (550, 551), (551, 553), (553, 554), (554, 555), (555, 556), (556, 558), (559, 561), (561, 562), (562, 563), (563, 564), (565, 567), (567, 568), (568, 569), (570, 572), (572, 573), (573, 574), (574, 575), (576, 578), (578, 579), (579, 580), (580, 581), (581, 582), (582, 583), (583, 584), (584, 585), (585, 588), (588, 589), (590, 592), (593, 595), (595, 596), (596, 597), (597, 598), (599, 601), (602, 605), (0, 0)], [(0, 0), (0, 1), (1, 4), (5, 7), (7, 8), (9, 11), (11, 12), (12, 13), (13, 14), (15, 17), (17, 18), (19, 21), (22, 24), (24, 25), (26, 29), (29, 30), (31, 33), (33, 34), (34, 35), (0, 0), (520, 521), (521, 522), (523, 526), (526, 527), (528, 530), (530, 531), (532, 534), (534, 536), (536, 537), (538, 540), (541, 543), (543, 544), (544, 545), (546, 547), (547, 548), (548, 550), (550, 551), (551, 553), (553, 554), (554, 555), (555, 556), (556, 558), (559, 561), (561, 562), (562, 563), (563, 564), (565, 567), (567, 568), (568, 569), (570, 572), (572, 573), (573, 574), (574, 575), (576, 578), (578, 579), (579, 580), (580, 581), (581, 582), (582, 583), (583, 584), (584, 585), (585, 588), (588, 589), (590, 592), (593, 595), (595, 596), (596, 597), (597, 598), (599, 601), (602, 605), (605, 606), (607, 610), (610, 611), (611, 614), (614, 615), (615, 616), (617, 619), (619, 620), (621, 623), (623, 624), (624, 626), (627, 628), (628, 629), (630, 631), (631, 633), (634, 637), (637, 638), (638, 639), (640, 643), (644, 647), (648, 650), (650, 651), (652, 655), (655, 656), (657, 659), (659, 660), (661, 663), (663, 664), (665, 667), (0, 0)], [(0, 0), (0, 1), (1, 4), (5, 7), (7, 8), (9, 11), (11, 12), (12, 13), (13, 14), (15, 17), (17, 18), (19, 21), (22, 24), (24, 25), (26, 29), (29, 30), (31, 33), (33, 34), (34, 35), (0, 0), (570, 572), (572, 573), (573, 574), (574, 575), (576, 578), (578, 579), (579, 580), (580, 581), (581, 582), (582, 583), (583, 584), (584, 585), (585, 588), (588, 589), (590, 592), (593, 595), (595, 596), (596, 597), (597, 598), (599, 601), (602, 605), (605, 606), (607, 610), (610, 611), (611, 614), (614, 615), (615, 616), (617, 619), (619, 620), (621, 623), (623, 624), (624, 626), (627, 628), (628, 629), (630, 631), (631, 633), (634, 637), (637, 638), (638, 639), (640, 643), (644, 647), (648, 650), (650, 651), (652, 655), (655, 656), (657, 659), (659, 660), (661, 663), (663, 664), (665, 667), (667, 668), (669, 671), (672, 674), (674, 675), (676, 679), (680, 682), (682, 683), (684, 686), (687, 688), (688, 690), (691, 692), (692, 693), (694, 696), (697, 698), (698, 699), (700, 701), (701, 703), (704, 706), (706, 707), (708, 710), (711, 713), (713, 714), (714, 715), (716, 718), (718, 719), (720, 721), (721, 722), (723, 725), (725, 727), (0, 0)], [(0, 0), (0, 1), (1, 4), (5, 7), (7, 8), (9, 11), (11, 12), (12, 13), (13, 14), (15, 17), (17, 18), (19, 21), (22, 24), (24, 25), (26, 29), (29, 30), (31, 33), (33, 34), (34, 35), (0, 0), (621, 623), (623, 624), (624, 626), (627, 628), (628, 629), (630, 631), (631, 633), (634, 637), (637, 638), (638, 639), (640, 643), (644, 647), (648, 650), (650, 651), (652, 655), (655, 656), (657, 659), (659, 660), (661, 663), (663, 664), (665, 667), (667, 668), (669, 671), (672, 674), (674, 675), (676, 679), (680, 682), (682, 683), (684, 686), (687, 688), (688, 690), (691, 692), (692, 693), (694, 696), (697, 698), (698, 699), (700, 701), (701, 703), (704, 706), (706, 707), (708, 710), (711, 713), (713, 714), (714, 715), (716, 718), (718, 719), (720, 721), (721, 722), (723, 725), (725, 727), (727, 728), (0, 0)]]\n","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"]}]},{"cell_type":"code","source":["inputs = tokenizer(\n","    dataset[\"train\"][2:6][\"question\"],\n","    dataset[\"train\"][2:6][\"context\"],\n","    max_length=100,\n","    truncation=\"only_second\",\n","    stride=50,\n","    return_overflowing_tokens=True,\n","    return_offsets_mapping=True,\n",")\n","\n","print(f\"The 4 examples gave {len(inputs['input_ids'])} features.\")\n","print(f\"Here is where each comes from: {inputs['overflow_to_sample_mapping']}.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Stx0M9YZpmDf","executionInfo":{"status":"ok","timestamp":1707149748497,"user_tz":-540,"elapsed":30,"user":{"displayName":"심재윤","userId":"07193421856804560452"}},"outputId":"07f541e2-d385-4079-e091-9cd113345224"},"execution_count":88,"outputs":[{"output_type":"stream","name":"stdout","text":["The 4 examples gave 77 features.\n","Here is where each comes from: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3].\n"]}]},{"cell_type":"code","source":["#텍스트 데이터에서의 문자 위치: 자연어 처리에서 오프셋은 텍스트 내에서 특정 문자, 단어, 또는 구문의 위치를 나타냅니다.\n","#예를 들어, \"Hello, world!\"라는 문장에서 \"world\" 단어의 시작 오프셋은 7이 됩니다(0부터 시작하는 인덱싱을 가정할 때). 이는 오프셋이 텍스트의 시작부터 \"world\"의 시작 지점까지의 문자 수를 나타냅니다.\n","answers = dataset[\"train\"][2:6][\"answers\"]\n","start_positions = []\n","end_positions = []\n","\n","for i, offset in enumerate(inputs[\"offset_mapping\"]):\n","    #i: 0, 1, 2, 3, 4, ...\n","    #offset: (0, 0), (0, 1), (1, 4), ...\n","    sample_idx = inputs[\"overflow_to_sample_mapping\"][i]\n","    answer = answers[sample_idx]\n","    start_char = answer[\"answer_start\"][0]\n","    end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n","    #sequence_ids method의 기능 1)입력 구분: 쌍으로 된 입력에서 각 토큰이 어느 입력에 속하는지 구분. 예를 들어, BERT와 같은 모델에서 question과 context를 함께 입력할 때, 어떤 토큰이 질문에 속하고 어떤 토큰이 문단에 속하는지 알려줌.\n","    #special token 관리: special token(예: [CLS], [SEP] 등)을 어떻게 처리할지도 알려줍니다. 이러한 토큰은 입력 시퀀스를 구분하거나 특정 기능을 수행하는 데 사용\n","    #sequence_ids: [None, 0, 0, 0, ..., None, 1, 1, 1, ..., None] (각 token마다)\n","    #None: special token, 0: question, 1: context\n","    sequence_ids = inputs.sequence_ids(i)\n","    # print(sequence_ids)\n","\n","    # Find the start and end of the context\n","    idx = 0\n","    while sequence_ids[idx] != 1:\n","        idx += 1\n","    context_start = idx\n","    while sequence_ids[idx] == 1:\n","        idx += 1\n","    context_end = idx - 1\n","\n","    # If the answer is not fully inside the context, label is (0, 0)\n","    if offset[context_start][0] > start_char or offset[context_end][1] < end_char:\n","        start_positions.append(0)\n","        end_positions.append(0)\n","    else:\n","        # Otherwise it's the start and end token positions\n","        idx = context_start\n","        while idx <= context_end and offset[idx][0] <= start_char:\n","            idx += 1\n","        start_positions.append(idx - 1)\n","\n","        idx = context_end\n","        while idx >= context_start and offset[idx][1] >= end_char:\n","            idx -= 1\n","        end_positions.append(idx + 1)\n","\n","print(start_positions)\n","print(end_positions)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-8oVqrKhvHRD","executionInfo":{"status":"ok","timestamp":1707149748497,"user_tz":-540,"elapsed":26,"user":{"displayName":"심재윤","userId":"07193421856804560452"}},"outputId":"ca6a018b-5d5f-4bba-e9a5-d0686a4082f0"},"execution_count":89,"outputs":[{"output_type":"stream","name":"stdout","text":["[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 85, 52, 19, 0, 0, 0, 0, 0, 80, 51, 22, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 72, 40, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 81, 58, 35, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 89, 56, 23, 0, 0, 0, 0, 0, 81, 52, 23, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 78, 46, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 87, 64, 41, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"]}]},{"cell_type":"code","source":["idx = 20\n","sample_idx = inputs[\"overflow_to_sample_mapping\"][idx]\n","answer = answers[sample_idx][\"text\"][0]\n","\n","start = start_positions[idx]\n","end = end_positions[idx]\n","labeled_answer = tokenizer.decode(inputs[\"input_ids\"][idx][start : end + 1])\n","\n","print(f\"Theoretical answer: {answer}, labels give: {labeled_answer}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vtWER6Fk12IK","executionInfo":{"status":"ok","timestamp":1707149748497,"user_tz":-540,"elapsed":24,"user":{"displayName":"심재윤","userId":"07193421856804560452"}},"outputId":"c0f87e27-0776-4e7d-e724-2f6d7a0ea272"},"execution_count":90,"outputs":[{"output_type":"stream","name":"stdout","text":["Theoretical answer: 삼보테크놀로지, labels give: 삼보테크놀로지\n"]}]},{"cell_type":"code","source":["#BERT 모델에 맞게 max_length랑 stride 설정\n","max_length = 384\n","stride = 128\n","\n","def preprocess_training_examples(examples):\n","    questions = [q.strip() for q in examples[\"question\"]]\n","    inputs = tokenizer(\n","        questions,\n","        examples[\"context\"],\n","        max_length=max_length,\n","        truncation=\"only_second\",\n","        stride=stride,\n","        return_overflowing_tokens=True,\n","        return_offsets_mapping=True,\n","        padding=\"max_length\",\n","    )\n","\n","    # overflow_to_sample_mapping: 원래 text에서 max_length에 의해 나누어진 문장들이 어디서 온 문장들인지 구분해주기 위해 사용되는 list\n","    # 만약 question과 context가 각각 3 문장이었다면 [0, 0, 0, ..., 1, 1, 1, ..., 2, 2, 2, ...] 이런 식이었을 것.\n","    offset_mapping = inputs.pop(\"offset_mapping\")\n","    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n","    answers = examples[\"answers\"]\n","    start_positions = []\n","    end_positions = []\n","\n","    for i, offset in enumerate(offset_mapping):\n","        #answer 있는 index 찾기\n","        sample_idx = sample_map[i]\n","        answer = answers[sample_idx]\n","        start_char = answer[\"answer_start\"][0]\n","        end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n","        sequence_ids = inputs.sequence_ids(i)\n","\n","        # Find the start and end of the context\n","        idx = 0\n","        while sequence_ids[idx] != 1:\n","            idx += 1\n","        context_start = idx\n","        while sequence_ids[idx] == 1:\n","            idx += 1\n","        context_end = idx - 1\n","\n","        # If the answer is not fully inside the context, label is (0, 0)\n","        if offset[context_start][0] > start_char or offset[context_end][1] < end_char:\n","            start_positions.append(0)\n","            end_positions.append(0)\n","        else:\n","            # Otherwise it's the start and end token positions\n","            idx = context_start\n","            while idx <= context_end and offset[idx][0] <= start_char:\n","                idx += 1\n","            start_positions.append(idx - 1)\n","\n","            idx = context_end\n","            while idx >= context_start and offset[idx][1] >= end_char:\n","                idx -= 1\n","            end_positions.append(idx + 1)\n","\n","    inputs[\"start_positions\"] = start_positions\n","    inputs[\"end_positions\"] = end_positions\n","    return inputs"],"metadata":{"id":"sNpdrrzr3XP2","executionInfo":{"status":"ok","timestamp":1707149748497,"user_tz":-540,"elapsed":22,"user":{"displayName":"심재윤","userId":"07193421856804560452"}}},"execution_count":91,"outputs":[]},{"cell_type":"code","source":["train_dataset = dataset[\"train\"].map(\n","    preprocess_training_examples,\n","    batched=True,\n","    remove_columns=dataset[\"train\"].column_names,\n",")\n","len(dataset[\"train\"]), len(train_dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g7EhtrWX5ZRe","executionInfo":{"status":"ok","timestamp":1707149748497,"user_tz":-540,"elapsed":22,"user":{"displayName":"심재윤","userId":"07193421856804560452"}},"outputId":"8ce56720-a44f-420e-c602-fb919d2ebdef"},"execution_count":92,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(17554, 37586)"]},"metadata":{},"execution_count":92}]},{"cell_type":"code","source":["train_dataset"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h76UKpsth9Xg","executionInfo":{"status":"ok","timestamp":1707149748498,"user_tz":-540,"elapsed":21,"user":{"displayName":"심재윤","userId":"07193421856804560452"}},"outputId":"ec92472b-e1fe-4122-8d0d-89936a8b34f0"},"execution_count":93,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Dataset({\n","    features: ['input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions'],\n","    num_rows: 37586\n","})"]},"metadata":{},"execution_count":93}]},{"cell_type":"code","source":["def preprocess_validation_examples(examples):\n","    questions = [q.strip() for q in examples[\"question\"]]\n","    inputs = tokenizer(\n","        questions,\n","        examples[\"context\"],\n","        max_length=max_length,\n","        truncation=\"only_second\",\n","        stride=stride,\n","        return_overflowing_tokens=True,\n","        return_offsets_mapping=True,\n","        padding=\"max_length\",\n","    )\n","\n","    # train data와 preprocesss 차이점\n","    # answer의 위치를 나타낼 start_position과 end_positiion에 대한 정보 X\n","    # 대신 validation data를 구분하기 위한 guid와 word 위치를 나타내기 위한 offset mapping에 대한 정보 추가\n","\n","    # overflow_to_sample_mapping: 원래 text에서 max_length에 의해 나누어진 문장들이 어디서 온 문장들인지 구분해주기 위해 사용되는 list\n","    # 만약 question과 context가 각각 3 문장이었다면 [0, 0, 0, ..., 1, 1, 1, ..., 2, 2, 2, ...] 이런 식이었을 것.\n","    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n","    example_ids = []\n","\n","    for i in range(len(inputs[\"input_ids\"])):\n","        sample_idx = sample_map[i]\n","        example_ids.append(examples[\"guid\"][sample_idx])\n","\n","        sequence_ids = inputs.sequence_ids(i)\n","        offset = inputs[\"offset_mapping\"][i]\n","        #offset이 1이면 context니까  offset mapping\n","        inputs[\"offset_mapping\"][i] = [\n","            o if sequence_ids[k] == 1 else None for k, o in enumerate(offset)\n","        ]\n","\n","    inputs[\"example_id\"] = example_ids\n","    return inputs"],"metadata":{"id":"fOtjo-qlLm1Q","executionInfo":{"status":"ok","timestamp":1707149748498,"user_tz":-540,"elapsed":20,"user":{"displayName":"심재윤","userId":"07193421856804560452"}}},"execution_count":94,"outputs":[]},{"cell_type":"code","source":["validation_dataset = dataset[\"validation\"].map(\n","    preprocess_validation_examples,\n","    batched=True,\n","    remove_columns=dataset[\"validation\"].column_names,\n",")\n","len(dataset[\"validation\"]), len(validation_dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oEk8p9xILqZ0","executionInfo":{"status":"ok","timestamp":1707149748498,"user_tz":-540,"elapsed":19,"user":{"displayName":"심재윤","userId":"07193421856804560452"}},"outputId":"5577cb86-02d4-4ebc-b3ca-4e2af7a362af"},"execution_count":95,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(5841, 12645)"]},"metadata":{},"execution_count":95}]},{"cell_type":"code","source":["validation_dataset"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RqeAuQXvxr3-","executionInfo":{"status":"ok","timestamp":1707149748498,"user_tz":-540,"elapsed":18,"user":{"displayName":"심재윤","userId":"07193421856804560452"}},"outputId":"72e422eb-4f09-4224-a521-a7885aabc87d"},"execution_count":96,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Dataset({\n","    features: ['input_ids', 'token_type_ids', 'attention_mask', 'offset_mapping', 'example_id'],\n","    num_rows: 12645\n","})"]},"metadata":{},"execution_count":96}]},{"cell_type":"code","source":["print(validation_dataset[0]['offset_mapping'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CDxkyA5XxdWG","executionInfo":{"status":"ok","timestamp":1707149748498,"user_tz":-540,"elapsed":16,"user":{"displayName":"심재윤","userId":"07193421856804560452"}},"outputId":"1fdcff6b-6df2-487b-fa10-b7b8e5d06bb9"},"execution_count":97,"outputs":[{"output_type":"stream","name":"stdout","text":["[None, None, None, None, None, None, None, None, None, None, None, None, None, None, [0, 3], [4, 7], [7, 8], [8, 10], [11, 13], [13, 14], [14, 15], [15, 16], [17, 19], [20, 22], [22, 23], [23, 24], [24, 25], [26, 28], [28, 29], [29, 30], [31, 32], [32, 35], [36, 39], [40, 42], [42, 43], [43, 44], [45, 48], [48, 49], [49, 50], [51, 53], [54, 56], [56, 58], [58, 59], [60, 62], [62, 63], [63, 64], [65, 67], [68, 71], [72, 75], [76, 78], [78, 79], [79, 80], [81, 84], [84, 85], [85, 87], [88, 90], [90, 91], [91, 92], [93, 96], [96, 97], [97, 98], [99, 102], [103, 104], [104, 105], [105, 106], [106, 107], [107, 108], [109, 110], [110, 111], [111, 112], [112, 113], [113, 114], [115, 116], [116, 117], [117, 118], [118, 119], [119, 120], [121, 122], [122, 123], [123, 124], [124, 125], [126, 127], [128, 129], [129, 130], [130, 131], [132, 133], [133, 134], [135, 137], [137, 138], [139, 141], [141, 142], [142, 143], [143, 144], [145, 148], [149, 152], [153, 155], [155, 156], [156, 157], [158, 161], [162, 163], [164, 165], [165, 166], [167, 168], [168, 170], [170, 171], [172, 174], [174, 175], [176, 178], [178, 179], [180, 182], [182, 183], [184, 186], [186, 187], [187, 188], [189, 191], [191, 192], [193, 195], [195, 196], [197, 199], [199, 200], [201, 205], [206, 208], [208, 209], [209, 210], [211, 213], [213, 214], [215, 217], [217, 219], [219, 220], [221, 223], [224, 225], [226, 229], [229, 230], [231, 232], [233, 234], [235, 238], [238, 239], [240, 242], [242, 243], [243, 244], [245, 248], [248, 249], [250, 252], [252, 253], [254, 256], [257, 259], [259, 261], [262, 264], [264, 265], [265, 267], [267, 268], [269, 271], [271, 272], [273, 275], [276, 279], [280, 282], [282, 283], [283, 285], [285, 286], [287, 289], [289, 290], [291, 293], [293, 294], [295, 297], [297, 298], [298, 299], [299, 300], [301, 304], [305, 307], [307, 308], [309, 311], [311, 312], [312, 313], [314, 316], [316, 318], [319, 321], [321, 322], [323, 325], [326, 330], [330, 331], [332, 333], [333, 335], [336, 337], [337, 338], [338, 339], [339, 340], [340, 341], [342, 344], [345, 347], [348, 351], [352, 354], [354, 356], [357, 358], [358, 359], [360, 362], [362, 363], [364, 366], [366, 367], [368, 369], [369, 370], [371, 373], [373, 374], [375, 377], [377, 378], [379, 381], [381, 382], [383, 384], [384, 385], [386, 388], [388, 390], [390, 391], [392, 393], [394, 397], [398, 401], [402, 404], [404, 405], [406, 408], [408, 409], [409, 410], [411, 414], [415, 417], [417, 418], [419, 423], [423, 424], [425, 426], [426, 428], [429, 430], [430, 431], [431, 432], [432, 433], [433, 434], [435, 437], [438, 440], [441, 444], [445, 446], [447, 448], [448, 450], [450, 451], [452, 453], [453, 454], [454, 455], [456, 458], [458, 459], [460, 462], [462, 463], [463, 464], [465, 467], [467, 469], [469, 470], [471, 472], [473, 476], [476, 477], [478, 480], [480, 481], [481, 482], [483, 486], [486, 487], [487, 489], [489, 490], [491, 493], [493, 494], [494, 495], [496, 498], [498, 499], [500, 501], [501, 502], [502, 503], [503, 504], [504, 505], [506, 509], [510, 512], [512, 513], [514, 516], [516, 517], [517, 518], [518, 519], [520, 523], [523, 524], [525, 529], [529, 530], [530, 531], [532, 534], [535, 538], [539, 541], [541, 542], [543, 544], [544, 545], [545, 546], [546, 547], [547, 548], [549, 552], [552, 553], [554, 556], [557, 558], [559, 561], [561, 562], [563, 564], [564, 565], [566, 568], [568, 569], [570, 572], [572, 573], [573, 574], [574, 575], [576, 578], [579, 581], [581, 582], [583, 584], [584, 585], [585, 587], [588, 590], [590, 591], [592, 594], [594, 595], [595, 596], [597, 598], [598, 599], [599, 600], [600, 601], [602, 603], [604, 607], [607, 608], [609, 611], [611, 612], [612, 613], [614, 617], [617, 618], [618, 620], [620, 621], [622, 624], [624, 625], [625, 626], [627, 628], [629, 630], [630, 631], [631, 632], [632, 633], [634, 636], [636, 637], [637, 638], [639, 642], [642, 644], [645, 647], [647, 648], [649, 652], [653, 655], [656, 658], [658, 659], [660, 662], [662, 663], [663, 664], [664, 665], [666, 667], [668, 671], [671, 672], [672, 673], [674, 676], [676, 677], [677, 678], [679, 682], [682, 683], [683, 684], [684, 685], [686, 688], [688, 689], [689, 691], [692, 694], [694, 696], [696, 697], [698, 700], [701, 703], [704, 706], [706, 707], [708, 710], [710, 711], [711, 712], [712, 713], [714, 716], [716, 718], [718, 719], [719, 720], [721, 723], [723, 724], None]\n"]}]},{"cell_type":"code","source":["validation_dataset['example_id'][0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"UCxRAp_6kSsw","executionInfo":{"status":"ok","timestamp":1707149748500,"user_tz":-540,"elapsed":16,"user":{"displayName":"심재윤","userId":"07193421856804560452"}},"outputId":"a6d59f51-a9bf-4e9c-dabe-177bd7440a83"},"execution_count":98,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'klue-mrc-v1_dev_01891'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":98}]},{"cell_type":"markdown","source":["Post-processing"],"metadata":{"id":"PUwDhVGxL6_e"}},{"cell_type":"markdown","source":["Here we will change this process slightly because we don’t need to compute actual scores (just the predicted answer). This means we can skip the softmax step. To go faster, we also won’t score all the possible (start_token, end_token) pairs, but only the ones corresponding to the highest n_best logits (with n_best=20). Since we will skip the softmax, those scores will be logit scores, and will be obtained by taking the sum of the start and end logits (instead of the product, because of the rule\n","log\n","⁡\n","(\n","a\n","b\n",")\n","=\n","log\n","⁡\n","(\n","a\n",")\n","+\n","log\n","⁡\n","(\n","b\n",")\n","log(ab)=log(a)+log(b)).\n","\n","*굳이 softmax function을 이용해서 정확한 점수를 구하는 대신, 상위 20개의 logits만 구해서 이용하기*\n","\n","To demonstrate all of this, we will need some kind of predictions. Since we have not trained our model yet, we are going to use the default model for the QA pipeline to generate some predictions on a small part of the validation set. We can use the same processing function as before; because it relies on the global constant tokenizer, we just have to change that object to the tokenizer of the model we want to use temporarily:\n","\n","*이 모든 것을 입증하기 위해서는 일종의 예측이 필요합니다. 아직 모델을 훈련하지 않았기 때문에 QA 파이프라인의 기본 모델을 사용하여 검증 세트의 작은 부분에 대한 예측을 생성할 것입니다. 이전과 동일한 처리 기능을 사용할 수 있습니다. 글로벌 상수 토큰화기에 의존하기 때문에 해당 개체를 임시로 사용하려는 모델의 토큰화기로 변경하면 됩니다:*"],"metadata":{"id":"x-EKSaff0UXQ"}},{"cell_type":"code","execution_count":99,"metadata":{"id":"JRADNu_X-Yrb","executionInfo":{"status":"ok","timestamp":1707149751014,"user_tz":-540,"elapsed":2529,"user":{"displayName":"심재윤","userId":"07193421856804560452"}}},"outputs":[],"source":["small_eval_set = dataset[\"validation\"].select(range(100))\n","#이미 QA에 학습되어 있는 tokenizer 사용\n","trained_checkpoint = \"distilbert-base-cased-distilled-squad\"\n","\n","tokenizer = AutoTokenizer.from_pretrained(trained_checkpoint)\n","eval_set = small_eval_set.map(\n","    preprocess_validation_examples,\n","    batched=True,\n","    remove_columns=dataset[\"validation\"].column_names,\n",")"]},{"cell_type":"code","source":["print(small_eval_set[\"answers\"][0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GKVtwaUvBBLm","executionInfo":{"status":"ok","timestamp":1707149751014,"user_tz":-540,"elapsed":6,"user":{"displayName":"심재윤","userId":"07193421856804560452"}},"outputId":"176d96be-0e4c-4dcb-b81d-b73f3bbc340b"},"execution_count":100,"outputs":[{"output_type":"stream","name":"stdout","text":["{'answer_start': [666, 666], 'text': ['뉴 740Li 25주년 에디션', '뉴 740Li 25주년']}\n"]}]},{"cell_type":"code","source":["#원래 tokenizer로 돌아오기\n","tokenizer = AutoTokenizer.from_pretrained(\"klue/bert-base\")"],"metadata":{"id":"Ah3D3xACMusM","executionInfo":{"status":"ok","timestamp":1707149751651,"user_tz":-540,"elapsed":641,"user":{"displayName":"심재윤","userId":"07193421856804560452"}}},"execution_count":101,"outputs":[]},{"cell_type":"code","source":["import torch\n","from transformers import AutoModelForQuestionAnswering\n","\n","eval_set_for_model = eval_set.remove_columns([\"example_id\", \"offset_mapping\"])\n","eval_set_for_model.set_format(\"torch\")\n","\n","device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","batch = {k: eval_set_for_model[k].to(device) for k in eval_set_for_model.column_names}\n","trained_model = AutoModelForQuestionAnswering.from_pretrained(trained_checkpoint).to(\n","    device\n",")\n","\n","with torch.no_grad():\n","    outputs = trained_model(**batch)"],"metadata":{"id":"yX9dO6vcNlLL","executionInfo":{"status":"ok","timestamp":1707149753714,"user_tz":-540,"elapsed":2067,"user":{"displayName":"심재윤","userId":"07193421856804560452"}}},"execution_count":102,"outputs":[]},{"cell_type":"code","source":["#Trainer가 prediction을 Numpy array로 반환하기 때문에 start_logits과 end_logits을 Numpy array로 변환\n","#시작점의 로짓 점수를 추출하고, 이를 CPU 메모리로 이동시킨 후, NumPy 배열로 변환하는 과정을 수행\n","start_logits = outputs.start_logits.cpu().numpy()\n","end_logits = outputs.end_logits.cpu().numpy()"],"metadata":{"id":"VVBI3jIdNm-j","executionInfo":{"status":"ok","timestamp":1707149755166,"user_tz":-540,"elapsed":1456,"user":{"displayName":"심재윤","userId":"07193421856804560452"}}},"execution_count":103,"outputs":[]},{"cell_type":"code","source":["import collections\n","\n","example_to_features = collections.defaultdict(list)\n","for idx, feature in enumerate(eval_set):\n","    example_to_features[feature[\"example_id\"]].append(idx)"],"metadata":{"id":"vKUqrW8RNoz5","executionInfo":{"status":"ok","timestamp":1707149755166,"user_tz":-540,"elapsed":4,"user":{"displayName":"심재윤","userId":"07193421856804560452"}}},"execution_count":104,"outputs":[]},{"cell_type":"code","source":["#id를 통해서 index에 접근하기 위한 용도\n","example_to_features"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y7rmubKxxwjm","executionInfo":{"status":"ok","timestamp":1707149755166,"user_tz":-540,"elapsed":4,"user":{"displayName":"심재윤","userId":"07193421856804560452"}},"outputId":"785e490f-5fbf-4bb1-f6bb-e36585b767b1"},"execution_count":105,"outputs":[{"output_type":"execute_result","data":{"text/plain":["defaultdict(list,\n","            {'klue-mrc-v1_dev_01891': [0],\n","             'klue-mrc-v1_dev_01842': [1],\n","             'klue-mrc-v1_dev_03566': [2],\n","             'klue-mrc-v1_dev_02673': [3],\n","             'klue-mrc-v1_dev_05664': [4],\n","             'klue-mrc-v1_dev_00170': [5],\n","             'klue-mrc-v1_dev_04276': [6],\n","             'klue-mrc-v1_dev_03749': [7, 8],\n","             'klue-mrc-v1_dev_00114': [9],\n","             'klue-mrc-v1_dev_04087': [10],\n","             'klue-mrc-v1_dev_01835': [11],\n","             'klue-mrc-v1_dev_00391': [12],\n","             'klue-mrc-v1_dev_01064': [13],\n","             'klue-mrc-v1_dev_04162': [14, 15],\n","             'klue-mrc-v1_dev_04695': [16],\n","             'klue-mrc-v1_dev_00280': [17],\n","             'klue-mrc-v1_dev_03416': [18],\n","             'klue-mrc-v1_dev_01024': [19],\n","             'klue-mrc-v1_dev_01421': [20],\n","             'klue-mrc-v1_dev_01806': [21],\n","             'klue-mrc-v1_dev_03432': [22],\n","             'klue-mrc-v1_dev_04169': [23],\n","             'klue-mrc-v1_dev_04030': [24, 25],\n","             'klue-mrc-v1_dev_04525': [26],\n","             'klue-mrc-v1_dev_01356': [27],\n","             'klue-mrc-v1_dev_01459': [28],\n","             'klue-mrc-v1_dev_00974': [29],\n","             'klue-mrc-v1_dev_00876': [30],\n","             'klue-mrc-v1_dev_01273': [31],\n","             'klue-mrc-v1_dev_00460': [32],\n","             'klue-mrc-v1_dev_01169': [33],\n","             'klue-mrc-v1_dev_00584': [34],\n","             'klue-mrc-v1_dev_00950': [35],\n","             'klue-mrc-v1_dev_01408': [36],\n","             'klue-mrc-v1_dev_00186': [37],\n","             'klue-mrc-v1_dev_01360': [38],\n","             'klue-mrc-v1_dev_01445': [39],\n","             'klue-mrc-v1_dev_00141': [40],\n","             'klue-mrc-v1_dev_01753': [41],\n","             'klue-mrc-v1_dev_05113': [42],\n","             'klue-mrc-v1_dev_05448': [43],\n","             'klue-mrc-v1_dev_05361': [44],\n","             'klue-mrc-v1_dev_05106': [45],\n","             'klue-mrc-v1_dev_00462': [46],\n","             'klue-mrc-v1_dev_00548': [47],\n","             'klue-mrc-v1_dev_03281': [48, 49],\n","             'klue-mrc-v1_dev_04832': [50],\n","             'klue-mrc-v1_dev_00668': [51],\n","             'klue-mrc-v1_dev_00901': [52],\n","             'klue-mrc-v1_dev_01017': [53],\n","             'klue-mrc-v1_dev_01226': [54],\n","             'klue-mrc-v1_dev_01291': [55],\n","             'klue-mrc-v1_dev_00406': [56],\n","             'klue-mrc-v1_dev_03061': [57],\n","             'klue-mrc-v1_dev_05327': [58, 59],\n","             'klue-mrc-v1_dev_00825': [60],\n","             'klue-mrc-v1_dev_01616': [61],\n","             'klue-mrc-v1_dev_03571': [62],\n","             'klue-mrc-v1_dev_00082': [63],\n","             'klue-mrc-v1_dev_04988': [64],\n","             'klue-mrc-v1_dev_00819': [65],\n","             'klue-mrc-v1_dev_00518': [66],\n","             'klue-mrc-v1_dev_03493': [67],\n","             'klue-mrc-v1_dev_01982': [68],\n","             'klue-mrc-v1_dev_00126': [69],\n","             'klue-mrc-v1_dev_00972': [70],\n","             'klue-mrc-v1_dev_00748': [71],\n","             'klue-mrc-v1_dev_01738': [72],\n","             'klue-mrc-v1_dev_01446': [73],\n","             'klue-mrc-v1_dev_01371': [74],\n","             'klue-mrc-v1_dev_00372': [75],\n","             'klue-mrc-v1_dev_01054': [76],\n","             'klue-mrc-v1_dev_00256': [77],\n","             'klue-mrc-v1_dev_02793': [78],\n","             'klue-mrc-v1_dev_03883': [79],\n","             'klue-mrc-v1_dev_02690': [80],\n","             'klue-mrc-v1_dev_04324': [81],\n","             'klue-mrc-v1_dev_05641': [82],\n","             'klue-mrc-v1_dev_03136': [83],\n","             'klue-mrc-v1_dev_05458': [84],\n","             'klue-mrc-v1_dev_05219': [85],\n","             'klue-mrc-v1_dev_04782': [86, 87],\n","             'klue-mrc-v1_dev_00308': [88],\n","             'klue-mrc-v1_dev_01747': [89],\n","             'klue-mrc-v1_dev_00831': [90],\n","             'klue-mrc-v1_dev_04825': [91],\n","             'klue-mrc-v1_dev_04349': [92],\n","             'klue-mrc-v1_dev_01407': [93],\n","             'klue-mrc-v1_dev_00069': [94],\n","             'klue-mrc-v1_dev_05505': [95],\n","             'klue-mrc-v1_dev_00441': [96],\n","             'klue-mrc-v1_dev_03938': [97],\n","             'klue-mrc-v1_dev_01209': [98],\n","             'klue-mrc-v1_dev_05204': [99],\n","             'klue-mrc-v1_dev_05318': [100, 101],\n","             'klue-mrc-v1_dev_05052': [102],\n","             'klue-mrc-v1_dev_03427': [103],\n","             'klue-mrc-v1_dev_00129': [104],\n","             'klue-mrc-v1_dev_04992': [105, 106],\n","             'klue-mrc-v1_dev_04198': [107]})"]},"metadata":{},"execution_count":105}]},{"cell_type":"code","source":["import numpy as np\n","\n","#context에서 가능한 모든 answer 후보들을 생성하고, 그 중에서 가장 좋은 answer를 선택하는 과정\n","n_best = 20\n","max_answer_length = 30\n","predicted_answers = []\n","\n","for example in small_eval_set:\n","    example_id = example[\"guid\"]\n","    context = example[\"context\"]\n","    answers = []\n","\n","    for feature_index in example_to_features[example_id]:\n","        #validation dataset에서 start_logit과 end_logit 찾기\n","        start_logit = start_logits[feature_index]\n","        end_logit = end_logits[feature_index]\n","        offsets = eval_set[\"offset_mapping\"][feature_index]\n","\n","        #start_index들을 내림차순으로 정리한 뒤, 가장 높은 점수를 가진 상위 20개의 index들을 start_indexes에 저장\n","        #end_index도 마찬가지\n","        start_indexes = np.argsort(start_logit)[-1 : -n_best - 1 : -1].tolist()\n","        end_indexes = np.argsort(end_logit)[-1 : -n_best - 1 : -1].tolist()\n","        for start_index in start_indexes:\n","            for end_index in end_indexes:\n","                # Skip answers that are not fully in the context\n","                if offsets[start_index] is None or offsets[end_index] is None:\n","                    continue\n","                # Skip answers with a length that is either < 0 or > max_answer_length.\n","                if (\n","                    end_index < start_index\n","                    or end_index - start_index + 1 > max_answer_length\n","                ):\n","                    continue\n","\n","                #조건에 맞는 answer를 answers 리스트에 추가\n","                answers.append(\n","                    {\n","                        \"text\": context[offsets[start_index][0] : offsets[end_index][1]],\n","                        \"logit_score\": start_logit[start_index] + end_logit[end_index],\n","                    }\n","                )\n","\n","    #가장 좋은 결과 따로 저장\n","    best_answer = max(answers, key=lambda x: x[\"logit_score\"])\n","    predicted_answers.append({\"id\": example_id, \"prediction_text\": best_answer[\"text\"]})"],"metadata":{"id":"Lzpqo6FwNrSO","executionInfo":{"status":"ok","timestamp":1707149775669,"user_tz":-540,"elapsed":20506,"user":{"displayName":"심재윤","userId":"07193421856804560452"}}},"execution_count":106,"outputs":[]},{"cell_type":"code","source":["!pip install rouge_score"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ut_FzC-H51HK","executionInfo":{"status":"ok","timestamp":1707149779925,"user_tz":-540,"elapsed":4269,"user":{"displayName":"심재윤","userId":"07193421856804560452"}},"outputId":"f0be95e5-0cb7-4828-ea62-c3e204db5d37"},"execution_count":107,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: rouge_score in /usr/local/lib/python3.10/dist-packages (0.1.2)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.8.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.23.5)\n","Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.16.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (1.3.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (2023.12.25)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (4.66.1)\n"]}]},{"cell_type":"code","source":["import evaluate\n","\n","#이 metric을 이용하면 f1 score와 exact_match(em) 두 개를 동시에 구할 수 있다\n","metric = evaluate.load(\"squad\")"],"metadata":{"id":"iia9tjUDNsX6","executionInfo":{"status":"ok","timestamp":1707149781523,"user_tz":-540,"elapsed":1612,"user":{"displayName":"심재윤","userId":"07193421856804560452"}}},"execution_count":108,"outputs":[]},{"cell_type":"code","source":["theoretical_answers = [\n","    {\"id\": ex[\"guid\"], \"answers\": ex[\"answers\"]} for ex in small_eval_set\n","]"],"metadata":{"id":"k4R9ckmLNthn","executionInfo":{"status":"ok","timestamp":1707149781523,"user_tz":-540,"elapsed":15,"user":{"displayName":"심재윤","userId":"07193421856804560452"}}},"execution_count":109,"outputs":[]},{"cell_type":"code","source":["print(predicted_answers[0])\n","print(theoretical_answers[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xCK14P9ANukI","executionInfo":{"status":"ok","timestamp":1707149781524,"user_tz":-540,"elapsed":14,"user":{"displayName":"심재윤","userId":"07193421856804560452"}},"outputId":"5886632c-1e0d-4ab5-b193-7a92327ffc42"},"execution_count":110,"outputs":[{"output_type":"stream","name":"stdout","text":["{'id': 'klue-mrc-v1_dev_01891', 'prediction_text': 'BMW'}\n","{'id': 'klue-mrc-v1_dev_01891', 'answers': {'answer_start': [666, 666], 'text': ['뉴 740Li 25주년 에디션', '뉴 740Li 25주년']}}\n"]}]},{"cell_type":"code","source":["metric.compute(predictions=predicted_answers, references=theoretical_answers)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J-saWCoQNxW6","executionInfo":{"status":"ok","timestamp":1707149781524,"user_tz":-540,"elapsed":13,"user":{"displayName":"심재윤","userId":"07193421856804560452"}},"outputId":"186d2ef5-466b-45a8-d1f9-1273166d4684"},"execution_count":111,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'exact_match': 0.0, 'f1': 0.8452380952380952}"]},"metadata":{},"execution_count":111}]},{"cell_type":"markdown","source":["metric"],"metadata":{"id":"W-R6_bjgN1xX"}},{"cell_type":"code","source":["from tqdm.auto import tqdm\n","\n","\n","def compute_metrics(start_logits, end_logits, features, examples):\n","    example_to_features = collections.defaultdict(list)\n","    for idx, feature in enumerate(features):\n","        example_to_features[feature[\"example_id\"]].append(idx)\n","\n","    predicted_answers = []\n","    for example in tqdm(examples):\n","        example_id = example[\"guid\"]\n","        context = example[\"context\"]\n","        answers = []\n","\n","        #위에 코드랑 같은 원리\n","        # Loop through all features associated with that example\n","        for feature_index in example_to_features[example_id]:\n","            start_logit = start_logits[feature_index]\n","            end_logit = end_logits[feature_index]\n","            offsets = features[feature_index][\"offset_mapping\"]\n","\n","            start_indexes = np.argsort(start_logit)[-1 : -n_best - 1 : -1].tolist()\n","            end_indexes = np.argsort(end_logit)[-1 : -n_best - 1 : -1].tolist()\n","            for start_index in start_indexes:\n","                for end_index in end_indexes:\n","                    # Skip answers that are not fully in the context\n","                    if offsets[start_index] is None or offsets[end_index] is None:\n","                        continue\n","                    # Skip answers with a length that is either < 0 or > max_answer_length\n","                    if (\n","                        end_index < start_index\n","                        or end_index - start_index + 1 > max_answer_length\n","                    ):\n","                        continue\n","\n","                    answer = {\n","                        \"text\": context[offsets[start_index][0] : offsets[end_index][1]],\n","                        \"logit_score\": start_logit[start_index] + end_logit[end_index],\n","                    }\n","                    answers.append(answer)\n","\n","        # Select the answer with the best score\n","        if len(answers) > 0:\n","            best_answer = max(answers, key=lambda x: x[\"logit_score\"])\n","            predicted_answers.append(\n","                {\"id\": example_id, \"prediction_text\": best_answer[\"text\"]}\n","            )\n","        else:\n","            predicted_answers.append({\"id\": example_id, \"prediction_text\": \"\"})\n","\n","    theoretical_answers = [{\"id\": ex[\"guid\"], \"answers\": ex[\"answers\"]} for ex in examples]\n","    return metric.compute(predictions=predicted_answers, references=theoretical_answers)"],"metadata":{"id":"q4suGAc1N23V","executionInfo":{"status":"ok","timestamp":1707149781524,"user_tz":-540,"elapsed":10,"user":{"displayName":"심재윤","userId":"07193421856804560452"}}},"execution_count":112,"outputs":[]},{"cell_type":"code","source":["compute_metrics(start_logits, end_logits, eval_set, small_eval_set)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":67,"referenced_widgets":["38e049934cef4df1988f4d24e2979fc8","36b3c0ba69434efd806f0232b61eb36d","e1904302eee54c4887ec74b1ae025d06","52cbfc651c224133a958f684f3274a5c","2bcc294d42d94f0b8be54b00efe0bf1e","9c10ea42be3940ecb26916486cf615db","aca4be34c25545caa9daee2c8244f732","9fd5148963af4d65bc1d0943eb402a70","b8db0b470b3349e188bc272c1c8225f9","16374e57a4774dcd8e373187e7299397","0dacebf5be324a6f8fb04718c80ab60b"]},"id":"0Ul1etjXN3UQ","executionInfo":{"status":"ok","timestamp":1707149782180,"user_tz":-540,"elapsed":666,"user":{"displayName":"심재윤","userId":"07193421856804560452"}},"outputId":"a114998d-98ef-41e9-8861-52f980974e1e"},"execution_count":113,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/100 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"38e049934cef4df1988f4d24e2979fc8"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["{'exact_match': 0.0, 'f1': 0.8452380952380952}"]},"metadata":{},"execution_count":113}]},{"cell_type":"markdown","metadata":{"id":"YzILLRzB-YrZ"},"source":["## Train"]},{"cell_type":"code","source":["model = AutoModelForQuestionAnswering.from_pretrained(\"klue/bert-base\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":161,"referenced_widgets":["a7177a1861bd4b4791aae5d58a155f56","08d975b6632b4514a610d85d533f16fa","150a59ae8ef247bca80504ff4e2e81da","f9bfc1f515ca46cebd6bddf001fd9daf","9214b25ff70344de876312a8489de184","0719aecfc3cf4b07bc3af4b43146cfba","5716f9c9a0f943cf92d27d56dce7c478","1f1e4c91c9014c0d97017ddeb409d621","8274a49d49a04a77bc1c21dbe185b27b","72e14d8181d64a75a3193a662026ff20","4821ba337781416a8a3f4d0b870a8c96"]},"id":"6R7hbJ-zN6b9","executionInfo":{"status":"ok","timestamp":1707149791005,"user_tz":-540,"elapsed":8832,"user":{"displayName":"심재윤","userId":"07193421856804560452"}},"outputId":"a6aefb5f-da78-4f53-dac2-d709bdd630c5"},"execution_count":114,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/424M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a7177a1861bd4b4791aae5d58a155f56"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at klue/bert-base were not used when initializing BertForQuestionAnswering: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","source":["from transformers import TrainingArguments\n","\n","training_args = TrainingArguments(\n","    \"klue-bert-base-finetuned-mrc\",\n","    evaluation_strategy=\"no\",\n","    save_strategy=\"epoch\",\n","    learning_rate=2e-5,\n","    num_train_epochs=3,\n","    weight_decay=0.01,\n","    fp16=True,\n",")"],"metadata":{"id":"5YqgF8hLOdiS","executionInfo":{"status":"ok","timestamp":1707149791005,"user_tz":-540,"elapsed":6,"user":{"displayName":"심재윤","userId":"07193421856804560452"}}},"execution_count":115,"outputs":[]},{"cell_type":"code","source":["from transformers import Trainer\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=validation_dataset,\n","    tokenizer=tokenizer,\n",")\n","trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"ZH8tFsQbOHce","executionInfo":{"status":"ok","timestamp":1707153213930,"user_tz":-540,"elapsed":3422930,"user":{"displayName":"심재윤","userId":"07193421856804560452"}},"outputId":"56852a77-52dc-4833-eaa5-40825048687c"},"execution_count":116,"outputs":[{"output_type":"stream","name":"stderr","text":["Using amp half precision backend\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 37586\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 14097\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='14097' max='14097' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [14097/14097 57:00, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>2.097200</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>1.442900</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>1.342400</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>1.256100</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>1.191600</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>1.177600</td>\n","    </tr>\n","    <tr>\n","      <td>3500</td>\n","      <td>1.119600</td>\n","    </tr>\n","    <tr>\n","      <td>4000</td>\n","      <td>1.107200</td>\n","    </tr>\n","    <tr>\n","      <td>4500</td>\n","      <td>1.096900</td>\n","    </tr>\n","    <tr>\n","      <td>5000</td>\n","      <td>0.887700</td>\n","    </tr>\n","    <tr>\n","      <td>5500</td>\n","      <td>0.738000</td>\n","    </tr>\n","    <tr>\n","      <td>6000</td>\n","      <td>0.729100</td>\n","    </tr>\n","    <tr>\n","      <td>6500</td>\n","      <td>0.692800</td>\n","    </tr>\n","    <tr>\n","      <td>7000</td>\n","      <td>0.702100</td>\n","    </tr>\n","    <tr>\n","      <td>7500</td>\n","      <td>0.705600</td>\n","    </tr>\n","    <tr>\n","      <td>8000</td>\n","      <td>0.685000</td>\n","    </tr>\n","    <tr>\n","      <td>8500</td>\n","      <td>0.705000</td>\n","    </tr>\n","    <tr>\n","      <td>9000</td>\n","      <td>0.668900</td>\n","    </tr>\n","    <tr>\n","      <td>9500</td>\n","      <td>0.667400</td>\n","    </tr>\n","    <tr>\n","      <td>10000</td>\n","      <td>0.431400</td>\n","    </tr>\n","    <tr>\n","      <td>10500</td>\n","      <td>0.425000</td>\n","    </tr>\n","    <tr>\n","      <td>11000</td>\n","      <td>0.410000</td>\n","    </tr>\n","    <tr>\n","      <td>11500</td>\n","      <td>0.399000</td>\n","    </tr>\n","    <tr>\n","      <td>12000</td>\n","      <td>0.411400</td>\n","    </tr>\n","    <tr>\n","      <td>12500</td>\n","      <td>0.434600</td>\n","    </tr>\n","    <tr>\n","      <td>13000</td>\n","      <td>0.409600</td>\n","    </tr>\n","    <tr>\n","      <td>13500</td>\n","      <td>0.405400</td>\n","    </tr>\n","    <tr>\n","      <td>14000</td>\n","      <td>0.421800</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to klue-bert-base-finetuned-mrc/checkpoint-4699\n","Configuration saved in klue-bert-base-finetuned-mrc/checkpoint-4699/config.json\n","Model weights saved in klue-bert-base-finetuned-mrc/checkpoint-4699/pytorch_model.bin\n","tokenizer config file saved in klue-bert-base-finetuned-mrc/checkpoint-4699/tokenizer_config.json\n","Special tokens file saved in klue-bert-base-finetuned-mrc/checkpoint-4699/special_tokens_map.json\n","Saving model checkpoint to klue-bert-base-finetuned-mrc/checkpoint-9398\n","Configuration saved in klue-bert-base-finetuned-mrc/checkpoint-9398/config.json\n","Model weights saved in klue-bert-base-finetuned-mrc/checkpoint-9398/pytorch_model.bin\n","tokenizer config file saved in klue-bert-base-finetuned-mrc/checkpoint-9398/tokenizer_config.json\n","Special tokens file saved in klue-bert-base-finetuned-mrc/checkpoint-9398/special_tokens_map.json\n","Saving model checkpoint to klue-bert-base-finetuned-mrc/checkpoint-14097\n","Configuration saved in klue-bert-base-finetuned-mrc/checkpoint-14097/config.json\n","Model weights saved in klue-bert-base-finetuned-mrc/checkpoint-14097/pytorch_model.bin\n","tokenizer config file saved in klue-bert-base-finetuned-mrc/checkpoint-14097/tokenizer_config.json\n","Special tokens file saved in klue-bert-base-finetuned-mrc/checkpoint-14097/special_tokens_map.json\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=14097, training_loss=0.8102129768241151, metrics={'train_runtime': 3421.4055, 'train_samples_per_second': 32.957, 'train_steps_per_second': 4.12, 'total_flos': 2.2097474772028416e+16, 'train_loss': 0.8102129768241151, 'epoch': 3.0})"]},"metadata":{},"execution_count":116}]},{"cell_type":"code","source":["predictions, _, _ = trainer.predict(validation_dataset)\n","start_logits, end_logits = predictions\n","compute_metrics(start_logits, end_logits, validation_dataset, dataset[\"validation\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":182,"referenced_widgets":["7aeb8854417d4b10940731611ba673de","f341365ce5fc44ea86828ba386e28b69","9d1ee1609a2a4f0caebae35613feb6e7","5e0ebba18b6d4cf8b0619bd4870c9d6c","4c57a17d6af04919b8e1bd9c0dc83149","f76c8f84fabc48ae8d0df1502224d6c2","25b3560b33474125b4711ab7033e3484","e2afaffc6da24720a7e7f0526624db1f","4df4306e053743bbb1a6088e479d69fc","4a6910c845f14e92b308551cb7ddc55c","dde38e9ef06a4cb48d5b2a1a8d8f20f1"]},"id":"8DsbEOg3ORMQ","executionInfo":{"status":"ok","timestamp":1707153367499,"user_tz":-540,"elapsed":153586,"user":{"displayName":"심재윤","userId":"07193421856804560452"}},"outputId":"4027c2f4-c94a-43fe-a605-bab44ea20dfc"},"execution_count":117,"outputs":[{"output_type":"stream","name":"stderr","text":["The following columns in the test set  don't have a corresponding argument in `BertForQuestionAnswering.forward` and have been ignored: offset_mapping, example_id. If offset_mapping, example_id are not expected by `BertForQuestionAnswering.forward`,  you can safely ignore this message.\n","***** Running Prediction *****\n","  Num examples = 12645\n","  Batch size = 8\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1581' max='1581' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1581/1581 01:51]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/5841 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7aeb8854417d4b10940731611ba673de"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["{'exact_match': 67.7452491011813, 'f1': 72.05632232728473}"]},"metadata":{},"execution_count":117}]},{"cell_type":"code","source":["from transformers import pipeline\n","\n","# Replace this with your own checkpoint\n","model_checkpoint = \"/content/klue-bert-base-finetuned-mrc/checkpoint-14097\"\n","question_answerer = pipeline(\"question-answering\", model=model_checkpoint)\n","\n","context = \"\"\"\n","🤗 김치는 배추와 고추가루로 만듭니다. 김치에는 파김치, 물김치, 깍두기 등이 있습니다.\n","\"\"\"\n","question = \"김치는 무엇으로 만드나요?\"\n","question_answerer(question=question, context=context)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xLGDqGSSOUFR","executionInfo":{"status":"ok","timestamp":1707153369372,"user_tz":-540,"elapsed":1879,"user":{"displayName":"심재윤","userId":"07193421856804560452"}},"outputId":"ef698a76-eaf7-4a98-ce3e-e03531585545"},"execution_count":118,"outputs":[{"output_type":"stream","name":"stderr","text":["loading configuration file /content/klue-bert-base-finetuned-mrc/checkpoint-14097/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/klue-bert-base-finetuned-mrc/checkpoint-14097\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.17.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 32000\n","}\n","\n","loading configuration file /content/klue-bert-base-finetuned-mrc/checkpoint-14097/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"/content/klue-bert-base-finetuned-mrc/checkpoint-14097\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.17.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 32000\n","}\n","\n","loading weights file /content/klue-bert-base-finetuned-mrc/checkpoint-14097/pytorch_model.bin\n","All model checkpoint weights were used when initializing BertForQuestionAnswering.\n","\n","All the weights of BertForQuestionAnswering were initialized from the model checkpoint at /content/klue-bert-base-finetuned-mrc/checkpoint-14097.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n","Didn't find file /content/klue-bert-base-finetuned-mrc/checkpoint-14097/added_tokens.json. We won't load it.\n","loading file /content/klue-bert-base-finetuned-mrc/checkpoint-14097/vocab.txt\n","loading file /content/klue-bert-base-finetuned-mrc/checkpoint-14097/tokenizer.json\n","loading file None\n","loading file /content/klue-bert-base-finetuned-mrc/checkpoint-14097/special_tokens_map.json\n","loading file /content/klue-bert-base-finetuned-mrc/checkpoint-14097/tokenizer_config.json\n"]},{"output_type":"execute_result","data":{"text/plain":["{'score': 0.5999550223350525, 'start': 7, 'end': 16, 'answer': '배추와 고추가루로'}"]},"metadata":{},"execution_count":118}]}]}
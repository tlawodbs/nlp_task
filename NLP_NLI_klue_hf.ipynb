{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1A_XWTiTE6rB12VruhSzoIeSvXz3PITup","authorship_tag":"ABX9TyMBU1D8mCf3qluPysU4vljJ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"2d6ab320b22847a49ff0f6a8a36e2aea":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3a76b755a89f4cdb95b8efb023bc2ea6","IPY_MODEL_1c2260d0681f4cd0a44cb5a15f233f26","IPY_MODEL_35b50674af4a4fcab8068aaf2ad5ac76"],"layout":"IPY_MODEL_7eba32a5738a42e395ed766f0527aa60"}},"3a76b755a89f4cdb95b8efb023bc2ea6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dc843f1dbdd240e096defe82b7c58563","placeholder":"​","style":"IPY_MODEL_6e09ac4f400649bba919d8b05ee8d32f","value":"Map: 100%"}},"1c2260d0681f4cd0a44cb5a15f233f26":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_279b281b7ebf4dc0b22f4b1472d4ec80","max":3000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b36832e74dd74568b23555859795a354","value":3000}},"35b50674af4a4fcab8068aaf2ad5ac76":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4542ce9e71524f498020438d325d6499","placeholder":"​","style":"IPY_MODEL_49408ef451f74861b65bf3d8eaf68e9a","value":" 3000/3000 [00:01&lt;00:00, 2512.96 examples/s]"}},"7eba32a5738a42e395ed766f0527aa60":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dc843f1dbdd240e096defe82b7c58563":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6e09ac4f400649bba919d8b05ee8d32f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"279b281b7ebf4dc0b22f4b1472d4ec80":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b36832e74dd74568b23555859795a354":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4542ce9e71524f498020438d325d6499":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"49408ef451f74861b65bf3d8eaf68e9a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["#Setting"],"metadata":{"id":"02IrD8zDzUes"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"clwzxjiQAZWw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1705764018522,"user_tz":-540,"elapsed":6114,"user":{"displayName":"심재윤","userId":"07193421856804560452"}},"outputId":"de310e56-e513-4a1e-f26e-318b329e6ea8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers==4.17 in /usr/local/lib/python3.10/dist-packages (4.17.0)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.16.1)\n","Collecting accelerate\n","  Downloading accelerate-0.26.1-py3-none-any.whl (270 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m270.9/270.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting evaluate\n","  Downloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.17) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.17) (0.20.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.17) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.17) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.17) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.17) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.17) (2.31.0)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.10/dist-packages (from transformers==4.17) (0.1.1)\n","Requirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.17) (0.15.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.17) (4.66.1)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (10.0.1)\n","Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n","Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n","Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu121)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.1)\n","Collecting responses<0.19 (from evaluate)\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.17) (4.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.17) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.17) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.17) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.17) (2023.11.17)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sacremoses->transformers==4.17) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sacremoses->transformers==4.17) (1.3.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n","Installing collected packages: responses, accelerate, evaluate\n","Successfully installed accelerate-0.26.1 evaluate-0.4.1 responses-0.18.0\n"]}],"source":["!pip install transformers==4.17 datasets accelerate evaluate"]},{"cell_type":"code","source":["from datasets import load_dataset\n","\n","dataset = load_dataset('klue', 'nli')\n","dataset"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UrLPInmOeXo1","executionInfo":{"status":"ok","timestamp":1705764020385,"user_tz":-540,"elapsed":1868,"user":{"displayName":"심재윤","userId":"07193421856804560452"}},"outputId":"a69643f0-d8ba-4a1e-b054-024ad7a05d61"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Dataset({\n","    features: ['guid', 'source', 'premise', 'hypothesis', 'label'],\n","    num_rows: 3000\n","})"]},"metadata":{},"execution_count":11}]},{"cell_type":"markdown","metadata":{"id":"peBXY9Mb-YrV"},"source":["# Fine-tune a pretrained model"]},{"cell_type":"markdown","metadata":{"id":"RDRA_mp3-YrW"},"source":["## Prepare a dataset"]},{"cell_type":"code","source":["# entailment(0), neutral(1), contradiction(2)\n","dataset['train'][0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_YpfT2GgjMGm","executionInfo":{"status":"ok","timestamp":1705764020385,"user_tz":-540,"elapsed":8,"user":{"displayName":"심재윤","userId":"07193421856804560452"}},"outputId":"5d9320dd-e3a0-4bff-a2fd-e0dc2339740f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'guid': 'klue-nli-v1_train_00000',\n"," 'source': 'NSMC',\n"," 'premise': '힛걸 진심 최고다 그 어떤 히어로보다 멋지다',\n"," 'hypothesis': '힛걸 진심 최고로 멋지다.',\n"," 'label': 0}"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["2d6ab320b22847a49ff0f6a8a36e2aea","3a76b755a89f4cdb95b8efb023bc2ea6","1c2260d0681f4cd0a44cb5a15f233f26","35b50674af4a4fcab8068aaf2ad5ac76","7eba32a5738a42e395ed766f0527aa60","dc843f1dbdd240e096defe82b7c58563","6e09ac4f400649bba919d8b05ee8d32f","279b281b7ebf4dc0b22f4b1472d4ec80","b36832e74dd74568b23555859795a354","4542ce9e71524f498020438d325d6499","49408ef451f74861b65bf3d8eaf68e9a"]},"executionInfo":{"elapsed":3610,"status":"ok","timestamp":1705764023989,"user":{"displayName":"심재윤","userId":"07193421856804560452"},"user_tz":-540},"id":"QKGGpqG8-YrY","outputId":"797c35c8-528a-4702-c3b5-be1ff4b08778"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/3000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d6ab320b22847a49ff0f6a8a36e2aea"}},"metadata":{}}],"source":["from transformers import AutoTokenizer\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"klue/bert-base\")\n","\n","def tokenize_function(examples):\n","    return tokenizer(examples['premise'], examples['hypothesis'], padding=\"max_length\", truncation=True)\n","\n","tokenized_datasets = dataset.map(tokenize_function, batched=True)"]},{"cell_type":"code","source":["tokenized_datasets['train']"],"metadata":{"id":"Z7iN9J9NhnYH","executionInfo":{"status":"ok","timestamp":1705764023989,"user_tz":-540,"elapsed":5,"user":{"displayName":"심재윤","userId":"07193421856804560452"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"6f6feb8d-9610-47c0-b13a-eb0e87744fcb"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Dataset({\n","    features: ['guid', 'source', 'premise', 'hypothesis', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n","    num_rows: 24998\n","})"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lQzY1E2_-YrZ"},"outputs":[],"source":["small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(500))\n","small_eval_dataset = tokenized_datasets[\"validation\"].shuffle(seed=42).select(range(500))"]},{"cell_type":"markdown","metadata":{"id":"YzILLRzB-YrZ"},"source":["## Train"]},{"cell_type":"markdown","metadata":{"id":"e9tr02Sz-Yra"},"source":["## Train with PyTorch Trainer"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2609,"status":"ok","timestamp":1705764026595,"user":{"displayName":"심재윤","userId":"07193421856804560452"},"user_tz":-540},"id":"swYplWix-Yra","outputId":"41f2a8b9-8781-48c8-ac2b-46506f6956e8"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at klue/bert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["from transformers import AutoModelForSequenceClassification\n","\n","model = AutoModelForSequenceClassification.from_pretrained(\"klue/bert-base\", num_labels=3)"]},{"cell_type":"markdown","metadata":{"id":"oNAUTpHM-Yra"},"source":["### Training hyperparameters"]},{"cell_type":"markdown","metadata":{"id":"QEhv24Qh-Yrb"},"source":["### Evaluate"]},{"cell_type":"code","source":["# 예시 training Arguments\n","# training_args = TrainingArguments(\n","#     output_dir='./results',          # output directory\n","#     num_train_epochs=1,              # total number of training epochs\n","#     per_device_train_batch_size=1,   # batch size per device during training\n","#     per_device_eval_batch_size=10,   # batch size for evaluation\n","#     warmup_steps=1000,               # number of warmup steps for learning rate scheduler\n","#     weight_decay=0.01,               # strength of weight decay\n","#     logging_dir='./logs',            # directory for storing logs\n","#     logging_steps=200,               # How often to print logs\n","#     do_train=True,                   # Perform training\n","#     do_eval=True,                    # Perform evaluation\n","#     evaluation_strategy=\"epoch\",     # evalute after eachh epoch\n","#     gradient_accumulation_steps=64,  # total number of steps before back propagation\n","#     fp16=True,                       # Use mixed precision\n","#     fp16_opt_level=\"02\",             # mixed precision mode\n","#     run_name=\"ProBert-BFD-MS\",       # experiment name\n","#     seed=3                           # Seed for experiment reproducibility 3x3\n","# )"],"metadata":{"id":"1X_PIjWCeWwf"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-DYGiFCh-Yrb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1705765032672,"user_tz":-540,"elapsed":453,"user":{"displayName":"심재윤","userId":"07193421856804560452"}},"outputId":"fb4041a4-a039-4a05-c079-3fcb57a22c5f"},"outputs":[{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"]}],"source":["from transformers import TrainingArguments, Trainer\n","\n","training_args = TrainingArguments(output_dir=\"test_trainer\", evaluation_strategy=\"epoch\", num_train_epochs=5)"]},{"cell_type":"markdown","metadata":{"id":"alQdvDsr-Yrc"},"source":["### Trainer"]},{"cell_type":"markdown","metadata":{"id":"bAizBUIS-Yrc"},"source":["Create a [Trainer](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer) object with your model, training arguments, training and test datasets, and evaluation function:"]},{"cell_type":"code","source":["import numpy as np\n","import evaluate\n","\n","metric = evaluate.load('accuracy')\n","\n","def compute_metrics(eval_pred):\n","    logits, labels = eval_pred\n","    predictions = np.argmax(logits, axis=-1)\n","    return metric.compute(predictions=predictions, references=labels)"],"metadata":{"id":"hdyvXwAHfKTI"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HL9Gn7_g-Yrc"},"outputs":[],"source":["trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=small_train_dataset,\n","    eval_dataset=small_eval_dataset,\n","    compute_metrics=compute_metrics,\n",")"]},{"cell_type":"markdown","metadata":{"id":"WBjptBXD-Yrc"},"source":["Then fine-tune your model by calling [train()](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer.train):"]},{"cell_type":"code","source":["small_train_dataset"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3zKQfOdgtmtm","executionInfo":{"status":"ok","timestamp":1705765037261,"user_tz":-540,"elapsed":6,"user":{"displayName":"심재윤","userId":"07193421856804560452"}},"outputId":"53603e0f-4a18-462e-cec6-a87adbf71300"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Dataset({\n","    features: ['guid', 'source', 'premise', 'hypothesis', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n","    num_rows: 500\n","})"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":932},"executionInfo":{"elapsed":321445,"status":"ok","timestamp":1705765358701,"user":{"displayName":"심재윤","userId":"07193421856804560452"},"user_tz":-540},"id":"Vo9oF-tJ-Yrc","outputId":"0b30aa53-6f98-4c11-d061-39380fda5216"},"outputs":[{"output_type":"stream","name":"stderr","text":["The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: guid, hypothesis, source, premise. If guid, hypothesis, source, premise are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 500\n","  Num Epochs = 5\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 315\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='315' max='315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [315/315 05:20, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>1.820071</td>\n","      <td>0.506000</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>No log</td>\n","      <td>2.909926</td>\n","      <td>0.536000</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>No log</td>\n","      <td>2.681127</td>\n","      <td>0.582000</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>No log</td>\n","      <td>3.401096</td>\n","      <td>0.536000</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>No log</td>\n","      <td>3.413868</td>\n","      <td>0.538000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: guid, hypothesis, source, premise. If guid, hypothesis, source, premise are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 500\n","  Batch size = 8\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: guid, hypothesis, source, premise. If guid, hypothesis, source, premise are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 500\n","  Batch size = 8\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: guid, hypothesis, source, premise. If guid, hypothesis, source, premise are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 500\n","  Batch size = 8\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: guid, hypothesis, source, premise. If guid, hypothesis, source, premise are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 500\n","  Batch size = 8\n","The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: guid, hypothesis, source, premise. If guid, hypothesis, source, premise are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 500\n","  Batch size = 8\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=315, training_loss=0.06772032843695747, metrics={'train_runtime': 321.3245, 'train_samples_per_second': 7.78, 'train_steps_per_second': 0.98, 'total_flos': 657783544320000.0, 'train_loss': 0.06772032843695747, 'epoch': 5.0})"]},"metadata":{},"execution_count":29}],"source":["trainer.train()"]},{"cell_type":"code","source":["small_train_dataset"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n0JXWTDTsJyj","executionInfo":{"status":"ok","timestamp":1705765358702,"user_tz":-540,"elapsed":6,"user":{"displayName":"심재윤","userId":"07193421856804560452"}},"outputId":"37e06a4b-08f4-495a-e67f-046a6a0523ea"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Dataset({\n","    features: ['guid', 'source', 'premise', 'hypothesis', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n","    num_rows: 500\n","})"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":["print(small_train_dataset[\"premise\"][1])\n","print(small_train_dataset[\"hypothesis\"][1])\n","print(small_train_dataset[\"label\"][1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JPhxOL5TXihG","executionInfo":{"status":"ok","timestamp":1705765563617,"user_tz":-540,"elapsed":343,"user":{"displayName":"심재윤","userId":"07193421856804560452"}},"outputId":"a42eaf1b-4aa6-49e8-a3ad-6d48723314b4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["오랜만에 가슴 벅찬 감동을 느꼈습니다\n","가슴 벅찬 감동은 오랜만입니다.\n","0\n"]}]},{"cell_type":"code","source":["trainer.evaluate()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":241},"id":"E1_k-1BdqF4m","executionInfo":{"status":"ok","timestamp":1705765587119,"user_tz":-540,"elapsed":17438,"user":{"displayName":"심재윤","userId":"07193421856804560452"}},"outputId":"3cd8b27a-018a-4671-f0ae-328c1593abe6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: guid, hypothesis, source, premise. If guid, hypothesis, source, premise are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 500\n","  Batch size = 8\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [63/63 00:16]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["{'eval_loss': 3.4138681888580322,\n"," 'eval_accuracy': 0.538,\n"," 'eval_runtime': 17.2114,\n"," 'eval_samples_per_second': 29.051,\n"," 'eval_steps_per_second': 3.66,\n"," 'epoch': 5.0}"]},"metadata":{},"execution_count":35}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iYoi2YEWj84q","colab":{"base_uri":"https://localhost:8080/","height":111},"executionInfo":{"status":"ok","timestamp":1705765974276,"user_tz":-540,"elapsed":326,"user":{"displayName":"심재윤","userId":"07193421856804560452"}},"outputId":"e0c0c147-e7e8-4d0d-bcd8-049b566f9b07"},"outputs":[{"output_type":"stream","name":"stderr","text":["***** Running Prediction *****\n","  Num examples = 1\n","  Batch size = 8\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='68' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [63/63 06:44]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["'entailment'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":41}],"source":["from datasets import Dataset\n","\n","label_dictionary = {0 : 'entailment', 1: 'neutral', 2: 'contradiction'}\n","\n","def text_classification(premise, hypothesis):\n","  example_data = {\n","      'label' : None,\n","      'premise' : premise,\n","      'hypothesis' : hypothesis,\n","      }\n","  tokenized_text = tokenizer(example_data['premise'], example_data['hypothesis'], padding=\"max_length\", truncation=True)\n","\n","  output = trainer.predict([tokenized_text])\n","  pred = np.argmax(output.predictions, axis=1)\n","  return label_dictionary[pred[0]]\n","\n","premise = \"오늘 저녁은 김치찌개 먹어야지\"\n","hypothesis = \"아 김치찌개 먹고 싶다\"\n","text_classification(premise, hypothesis)"]}]}